`r if(knitr:::is_latex_output()) '\\appendix'`

`r if(!knitr:::is_latex_output()) '# (APPENDIX) Appendix {-}'` 

<!--
If you feel it necessary to include an appendix, it goes here.
-->

# Plots for Chapter \@ref(Cleaning)

This appendix contains all interaction and main effect mean plots discussed in Chapter \@ref(Cleaning) for effects with a F-ratio greater than 2. It also contains appropriate violin plots for the main effect and two-way interactions to give us an understanding of the distribution of observations.

```{r acc-LC, echo=FALSE, message=FALSE}
colrs.emb <- c("#12694f","#188c69","#21c090","#3fdeaf", "#645fab","#7570b3","#9794c7","#bebcdc","#b65002","#d95f02","#fd750d","#fd8c35","#e7298a","#66a61e")
colrs.class <- c("#2a618d","#3881bc","#72a8d5","#91bbde","#e41a1c","#4daf4a","#327330")
shap.emb <- c(2, 6, 14, 17, 1, 10, 13, 16,3, 5, 0, 7, 12, 15)
shap.class <- c(15, 0, 7, 12, 1, 2, 6)
lt <- c(1,2,3,4,5,6,1,2,3,4,5,6,1,2)
ltc <- c(1,2,3,4,5,6,1)
```

(ref:acc-SC) $C \times E \times S$,  F-ratio = `r round(df.ano.acc$Frat[16],3)`. The difference in accuracy between filtering of stop words (no-yes) for each combination of classification and embedding method. Discriminant analyses are in blue. Logistic regression is red, and tree-based methods are in green. The median is a black triangle, and the mean is a grey circle.

```{r acc-SC, echo=FALSE, message=FALSE,warning=FALSE, tidy=TRUE,fig.cap="(ref:acc-SC)",fig.height=7, fig.align='center', cache=TRUE}
CES <- data.filter %>% group_by(ClassificationMethod,EmbeddingMethod,FilterStopwords) %>% 
  select(ClassificationMethod, EmbeddingMethod, FilterStopwords, Accuracy)
CES.no <- CES %>% subset(FilterStopwords == "No")
CES.yes <- CES %>% subset(FilterStopwords == "Yes")
CES.no$CES.acc.yes <- CES.yes$Accuracy
CES.new <- CES.no %>% summarize(CES.diff = Accuracy - CES.acc.yes)

CES.new %>% 
  ggplot(aes(x = ClassificationMethod, y = CES.diff, fill = ClassificationMethod)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~EmbeddingMethod,ncol = 4)+
  geom_hline(yintercept = 0, linetype = 'dashed', linewidth =1)+
  scale_fill_manual(values = colrs.class)+
  xlab("Classification Method") +
  ylab("Accuracy Rate")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),legend.position = "none")
```

(ref:StopClassVi-Acc) $C \times S$, F-ratio = `r round(df.ano.acc$Frat[8], 3)`. The effect of filtering stop words by classification method on accuracy. The median is a black triangle, and the mean is a grey circle.

```{r StopClassVi-Acc, echo = FALSE, tidy  = TRUE,warning=FALSE, fig.cap="(ref:StopClassVi-Acc)", fig.height=7,fig.align='center', cache=TRUE}
data.filter %>% ggplot(aes(x = FilterStopwords, y = Accuracy, fill = FilterStopwords)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~ClassificationMethod,ncol=2)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  xlab("Filter Stop Words?") +
  ylab("Accuracy Rate")+
  theme_bw()+
  theme(legend.position = "none")
```

(ref:StopEmbVi-Acc) $E \times S$, F-ratio = `r round(df.ano.acc$Frat[9], 3)`. The effect of filtering stop words by embedding method on accuracy. The median is a black triangle, and the mean is a grey circle.

```{r StopEmbVi-Acc, echo = FALSE, tidy  = TRUE,warning=FALSE,fig.cap="(ref:StopEmbVi-Acc)", fig.height=7, fig.align='center', cache=TRUE}
data.filter %>% 
  ggplot(aes(x = FilterStopwords, y = Accuracy, fill = FilterStopwords)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~EmbeddingMethod,ncol = 4)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', linewidth =1)+
  xlab("Classification Method") +
  ylab("Accuracy Rate")+
  theme_bw()+
  theme(legend.position = "none")
```

(ref:MinClassVi-Acc) $C \times F$, F-ratio = `r round(df.ano.acc$Frat[14],3)`. The effect of filtering based on minimum number of appearances by classification method on accuracy. The median is a black triangle, and the mean is a grey circle.

```{r MinClassVi-Acc, echo = FALSE, tidy  = TRUE,warning=FALSE,fig.cap="(ref:MinClassVi-Acc)", fig.height=7, fig.align='center', cache=TRUE}
data.filter %>% ggplot(aes(x = FilterMinAppear_F, y = Accuracy, fill = FilterMinAppear_F)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~ClassificationMethod,ncol = 2)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  xlab("Minimum Number of Appearances") +
  ylab("Accuracy Rate")+
  theme_bw()+
  theme(legend.position = "none")
```

(ref:MinEmbVi-Acc) $E \times F$, F-ratio = `r round(df.ano.acc$Frat[15],3)`. The effect of filtering based on minimum number of appearances by embedding method on accuracy. The median is a black triangle, and the mean is a grey circle.

```{r MinEmbVi-Acc, echo = FALSE, warning=FALSE, tidy  = TRUE,fig.cap="(ref:MinEmbVi-Acc)", fig.height=7, fig.align='center', cache=TRUE}
data.filter %>% 
  ggplot(aes(x = FilterMinAppear_F, y = Accuracy, fill = FilterMinAppear_F)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~EmbeddingMethod,ncol = 4)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  xlab("Minimum Number of Appearances") +
  ylab("Accuracy Rate")+
  theme_bw()+
  theme(legend.position = "none")
```

(ref:ClassEmbVi-Acc) $C \times E$, F-ratio = `r round(df.ano.acc$Frat[7], 3)`. The effect of classification method by embedding method on accuracy. Discriminant analyses are in blue. Logistic regression is red, and tree-based methods are in green. The median is a black triangle, and the mean is a grey circle.

```{r ClassEmbVi-Acc, echo = FALSE, tidy  = TRUE, warning=FALSE,fig.cap="(ref:ClassEmbVi-Acc)", fig.height=7, fig.align='center', cache=TRUE}
data.filter %>% 
  ggplot(aes(x = ClassificationMethod, y = Accuracy, fill = ClassificationMethod)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  facet_wrap(~EmbeddingMethod, ncol=4)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  scale_fill_manual(values = colrs.class) +
  xlab("Classification Method") +
  ylab("Accuracy Rate")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")
```

(ref:acc-Class) $C$, F-ratio = `r round(df.ano.acc$Frat[1], 3)`. The effect of classification method on accuracy. Discriminant analyses are in blue. Logistic regression is red, and tree-based methods are in green. The median is a black triangle, and the mean is a grey circle.

```{r acc-Class, echo=FALSE,warning=FALSE, message=FALSE, tidy=TRUE,fig.cap="(ref:acc-Class)", fig.align='center', cache=TRUE}
data.filter %>% 
  ggplot(aes(x = ClassificationMethod, y = Accuracy, fill = ClassificationMethod)) +
   geom_violin(trim=FALSE) +
   stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  scale_fill_manual(values = colrs.class)+
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Classification Method") +
  ylab("Accuracy Rate")
```

(ref:acc-Emb) $E$, F-ratio = `r round(df.ano.acc$Frat[2], 3)`. The effect of embedding method on accuracy. Word2Vec Continuous Bag of Words are in the blue-green shades, and Word2Vec Skip-Gram are in the blue-purple shades. GloVe is in the brown-orange shades. BERT is in pink, and PCA is in green. The median is a black triangle, and the mean is a grey circle.

```{r acc-Emb, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE,fig.cap="(ref:acc-Emb)",  fig.align='center', cache=TRUE}
data.filter %>% ggplot(aes(x = EmbeddingMethod, y = Accuracy, fill = EmbeddingMethod)) +
   geom_violin(trim=FALSE) +
   stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  scale_fill_manual(values = colrs.emb)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")+
  xlab("Embedding Method") +
  ylab("Accuracy Rate")
```

(ref:acc-Stop) $S$, F-ratio = `r round(df.ano.acc$Frat[3], 3)`. The effect of filtering stop words on accuracy. The median is a black triangle, and the mean is a grey circle.

```{r acc-Stop, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE,fig.cap="(ref:acc-Stop)",  fig.align='center', cache=TRUE}
data.filter %>% ggplot(aes(x = FilterStopwords, y = Accuracy, fill = FilterStopwords)) +
  geom_violin(trim=FALSE) +
   stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  theme_bw()+
  theme(legend.position = "none")+
  xlab("Filtering Stop Words?") +
  ylab("Accuracy Rate")
```

(ref:acc-Min) $F$, F-ratio = `r round(df.ano.acc$Frat[6], 3)`. The effect of filtering words based on minimum number of appearances on accuracy. The median is a black triangle, and the mean is a grey circle.

```{r acc-Min, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE, fig.cap="(ref:acc-Min)", fig.align='center', cache=TRUE}
data.filter %>% ggplot(aes(x = FilterMinAppear_F, y = Accuracy, fill = FilterMinAppear_F)) +
  geom_violin(trim=FALSE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  theme_bw()+
  theme(legend.position = "none")+
  xlab("Minimum Number of Appearances") +
  ylab("Accuracy Rate")
```

(ref:acc-Num) $N$, F-ratio = `r round(df.ano.acc$Frat[5], 3)`. The effect of filtering numbers on accuracy. The median is a black triangle, and the mean is a grey circle.

```{r acc-Num, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE,fig.cap="(ref:acc-Num)",  fig.align='center', cache=TRUE}
data.filter %>% ggplot(aes(x = FilterNumbers, y = Accuracy, fill = FilterNumbers)) +
  geom_violin(trim=FALSE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  xlab("Filter Numbers?") +
  ylab("Accuracy Rate")+
  theme_bw()+
  theme(legend.position = "none")
```

(ref:prec-FC) $C \times E \times F$, F-ratio = `r round(df.ano.prec$Frat[19], 3)`. The effect of classification method, embedding method, and filtering threshold on precision. Each classification method is represented by a letter. T is for classification tree, and G is for logistic regression. All others are based on the first letter of the method name. Only the means are plotted here. Violin plots are not used due to the number of levels of filtering threshold.

```{r prec-FC, echo=FALSE, message=FALSE,warning=FALSE,tidy=TRUE,fig.cap="(ref:prec-FC)", fig.align='center', cache=TRUE}
CEF.prec$ClassificationMethod <- gsub("LogReg", "G", CEF.prec$ClassificationMethod)
CEF.prec$ClassificationMethod <- gsub("LDA", "L", CEF.prec$ClassificationMethod)
CEF.prec$ClassificationMethod <- gsub("QDA", "Q", CEF.prec$ClassificationMethod)
CEF.prec$ClassificationMethod <- gsub("MDA", "M", CEF.prec$ClassificationMethod)
CEF.prec$ClassificationMethod <- gsub("FDA", "F", CEF.prec$ClassificationMethod)
CEF.prec$ClassificationMethod <- gsub("Tree", "T", CEF.prec$ClassificationMethod)
CEF.prec$ClassificationMethod <- gsub("RF", "R", CEF.prec$ClassificationMethod)
CEF.prec$ClassificationMethod <- factor(CEF.prec$ClassificationMethod, levels = c("L","Q","M","F","G","T","R"))

CEF.prec %>% ggplot() + aes(x = EmbeddingMethod, y=CEF.means, color = ClassificationMethod) + 
  geom_text(aes(label = ClassificationMethod)) +
  facet_wrap(~FilterMinAppear_F, ncol = 2)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  scale_color_manual(values = colrs.class)+
  xlab("Embedding Method") +
  ylab("Precision Rate")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")
```

(ref:prec-SC) $C \times E \times S$, F-ratio = `r round(df.ano.prec$Frat[16],3)`. The difference in precision between filtering of stop words (no-yes) for each combination of classification and embedding method. Discriminant analyses are in blue. Logistic regression is red, and tree-based methods are in green. The median is a black triangle, and the mean is a grey circle.

```{r prec-SC, echo=FALSE, message=FALSE,warning=FALSE,tidy=TRUE,fig.cap="(ref:prec-SC)", fig.height=7, fig.align='center', cache=TRUE}
CES.prec <- data.filter %>% group_by(ClassificationMethod,EmbeddingMethod,FilterStopwords) %>% 
  select(ClassificationMethod, EmbeddingMethod, FilterStopwords, Precision)
CES.prec.no <- CES.prec %>% subset(FilterStopwords == "No")
CES.prec.yes <- CES.prec %>% subset(FilterStopwords == "Yes")
CES.prec.no$CES.prec.yes <- CES.prec.yes$Precision
CES.prec.new <- CES.prec.no %>% summarize(CES.diff = Precision - CES.prec.yes)

CES.prec.new %>% 
  ggplot(aes(x = ClassificationMethod, y = CES.diff, fill = ClassificationMethod)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~EmbeddingMethod,ncol = 4)+
  geom_hline(yintercept = 0, linetype = 'dashed', linewidth =1)+
  scale_fill_manual(values = colrs.class)+
  xlab("Classification Method") +
  ylab("Precision Rate")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),legend.position = "none")
```

(ref:stopClassVi-prec) $C \times S$, F-ratio = `r round(df.ano.prec$Frat[8], 3)`. The effect of filtering stop words by classification method on precision. The median is a black triangle, and the mean is a grey circle.

```{r stopClassVi-prec, echo = FALSE, tidy  = TRUE,warning=FALSE, fig.cap="(ref:stopClassVi-prec)", fig.height=7, fig.align='center', cache=TRUE}
data.filter %>% ggplot(aes(x = FilterStopwords, y = Precision, fill = FilterStopwords)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~ClassificationMethod, ncol=2)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  xlab("Filter Stop Words?") +
  ylab("Precision Rate")+
  theme_bw()+
  theme(legend.position = "none")
```

(ref:StopEmbVi-prec) $E \times S$, F-ratio = `r round(df.ano.prec$Frat[9],3)`. The effect of filtering stop words by embedding method on precision. The median is a black triangle, and the mean is a grey circle.

```{r StopEmbVi-prec, echo = FALSE, tidy  = TRUE,warning=FALSE,fig.cap="(ref:StopEmbVi-prec)", fig.height=7, fig.align='center', cache=TRUE}
data.filter %>%
  ggplot(aes(x = FilterStopwords, y = Precision, fill = FilterStopwords)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~EmbeddingMethod, ncol=4)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  xlab("Filter Stop Words?") +
  ylab("Precision Rate")+
  theme_bw()+
  theme(legend.position = "none")
```

(ref:numClassVi-prec) $C \times N$, F-ratio = `r round(df.ano.prec$Frat[12],3)`. The effect of filtering numbers by classification method on precision. The median is a black triangle, and the mean is a grey circle.

```{r numClassVi-prec, echo = FALSE, tidy  = TRUE,warning=FALSE,fig.cap="(ref:numClassVi-prec)", fig.height=7, fig.align='center', cache=TRUE}
data.filter %>% ggplot(aes(x = FilterNumbers, y = Precision, fill = FilterNumbers)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~ClassificationMethod, ncol=2)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  xlab("Filter Numbers?") +
  ylab("Precision Rate")+
  theme_bw()+
  theme(legend.position = "none")
```

(ref:numEmbVi-prec) $E \times N$, F-ratio = `r round(df.ano.prec$Frat[13],3)`. The effect of filtering numbers by embedding method on precision. The median is a black triangle, and the mean is a grey circle.

```{r numEmbVi-prec, echo = FALSE, tidy  = TRUE,warning=FALSE,fig.cap="(ref:numEmbVi-prec)", fig.height=7, fig.align='center', cache=TRUE}
data.filter %>%
  ggplot(aes(x = FilterNumbers, y = Precision, fill = FilterNumbers)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~EmbeddingMethod, ncol=4)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  xlab("Filter Numbers?") +
  ylab("Precision Rate")+
  theme_bw()+
  theme(legend.position = "none") 
```

(ref:MinClassVi-prec) $C \times F$, F-ratio = `r round(df.ano.prec$Frat[14],3)`. The effect of filtering threshold by classification method on precision. The median is a black triangle, and the mean is a grey circle.

```{r MinClassVi-prec, echo = FALSE, tidy  = TRUE,warning=FALSE,fig.cap="(ref:MinClassVi-prec)", fig.height=7, fig.align='center', cache=TRUE}
data.filter %>% ggplot(aes(x = FilterMinAppear_F, y = Precision, fill = FilterMinAppear_F)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~ClassificationMethod,ncol = 2)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  xlab("Minimum Number of Appearances") +
  ylab("Precision Rate")+
  theme_bw()+
  theme(legend.position = "none")
```

(ref:MinEmbVi-prec) $E \times F$, F-ratio = `r round(df.ano.prec$Frat[15],3)`. The effect of filtering threshold by embedding method on precision. The median is a black triangle, and the mean is a grey circle.

```{r MinEmbVi-prec, echo = FALSE, tidy  = TRUE,warning=FALSE,fig.cap="(ref:MinEmbVi-prec)", fig.height=7, fig.align='center', cache=TRUE}
data.filter %>%
  ggplot(aes(x = FilterMinAppear_F, y = Precision, fill = FilterMinAppear_F)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~EmbeddingMethod,ncol = 4)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  xlab("Minimum Number of Appearances") +
  ylab("Precision Rate")+
  theme_bw()+
  theme(legend.position = "none") 
```

(ref:ClassEmbVi-Prec) $C \times E$, F-ratio = `r round(df.ano.prec$Frat[7],3)`. The effect of classification method by embedding method on precision. Discriminant analyses are in blue. Logistic regression is red, and tree-based methods are in green. The median is a black triangle, and the mean is a grey circle.

```{r ClassEmbVi-Prec, echo = FALSE, tidy  = TRUE,warning=FALSE,fig.cap="(ref:ClassEmbVi-Prec)", fig.height=7, fig.align='center', cache=TRUE}
data.filter %>% 
  ggplot(aes(x = ClassificationMethod, y = Precision, fill = ClassificationMethod)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~EmbeddingMethod, ncol=4)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  scale_fill_manual(values = colrs.class) +
  xlab("Embedding Method") +
  ylab("Precision Rate")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")
```

(ref:prec-Class) $C$, F-ratio = `r round(df.ano.prec$Frat[1],3)`. The effect of classification method on precision. Discriminant analyses are in blue. Logistic regression is red, and tree-based methods are in green. The median is a black triangle, and the mean is a grey circle.

```{r prec-Class, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE, fig.cap="(ref:prec-Class)", fig.align='center', cache=TRUE}
data.filter %>% 
  ggplot(aes(x = ClassificationMethod, y = Precision, fill = ClassificationMethod)) +
   geom_violin(trim=FALSE) +
   stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  scale_fill_manual(values = colrs.class)+
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Classification Method") +
  ylab("Precision Rate")
```

(ref:prec-Emb) $E$, F-ratio = `r round(df.ano.prec$Frat[2],3)`. The effect of embedding method on precision. Word2Vec Continuous Bag of Words are in the blue-green shades, and Word2Vec Skip-Gram are in the blue-purple shades. GloVe is in the brown-orange shades. BERT is in pink, and PCA is in green. The median is a black triangle, and the mean is a grey circle.

```{r prec-Emb, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE, fig.cap="(ref:prec-Emb)", fig.align='center', cache=TRUE}
data.filter %>% ggplot(aes(x = EmbeddingMethod, y = Precision, fill = EmbeddingMethod)) +
   geom_violin(trim=FALSE) +
   stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  scale_fill_manual(values = colrs.emb)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")+
  xlab("Embedding Method") +
  ylab("Precision Rate")
```

(ref:prec-Stop) $S$, F-ratio = `r round(df.ano.prec$Frat[3],3)`. The effect of filtering stop words on precision. The median is a black triangle, and the mean is a grey circle.

```{r prec-Stop, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE, fig.cap="(ref:prec-Stop)", fig.align='center', cache=TRUE}
data.filter %>% ggplot(aes(x = FilterStopwords, y = Precision, fill = FilterStopwords)) +
  geom_violin(trim=FALSE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Filter Stop Words?") +
  ylab("Precision Rate")
```

(ref:prec-Min) $F$, F-ratio = `r round(df.ano.prec$Frat[6],3)`. The effect of filtering threshold on precision. The median is a black triangle, and the mean is a grey circle.

```{r prec-Min, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE, fig.cap="(ref:prec-Min)", fig.align='center', cache=TRUE}
data.filter %>% ggplot(aes(x = FilterMinAppear_F, y = Precision, fill = FilterMinAppear_F)) +
  geom_violin(trim=FALSE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Minimum Number of Appearances") +
  ylab("Precision Rate")
```

(ref:prec-Low) $L$, F-ratio = `r round(df.ano.prec$Frat[4],3)`. The effect of converting to lowercase on precision. The median is a black triangle, and the mean is a grey circle.

```{r prec-Low, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE,fig.cap="(ref:prec-Low)", fig.align='center', cache=TRUE}
data.filter %>% ggplot(aes(x = ConvertLower, y = Precision, fill = ConvertLower)) +
  geom_violin(trim=FALSE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Convert Lower?") +
  ylab("Precision Rate")
```

(ref:sens-FC) $C \times E \times F$, F-ratio = `r round(df.ano.sens$Frat[19],3)`. The effect of classification method, embedding method, and filtering threshold on sensitivity. Each classification method is represented by a letter. T is for classification tree, and G is for logistic regression. All others are based on the first letter of the method name. Only the means are plotted here. Violin plots are not used due to the number of levels of filtering threshold.

```{r sens-FC, echo=FALSE, message=FALSE,warning=FALSE,tidy=TRUE,fig.cap="(ref:sens-FC)", fig.align='center', cache=TRUE}
CEF.sens$ClassificationMethod <- gsub("LogReg", "G", CEF.sens$ClassificationMethod)
CEF.sens$ClassificationMethod <- gsub("LDA", "L", CEF.sens$ClassificationMethod)
CEF.sens$ClassificationMethod <- gsub("QDA", "Q", CEF.sens$ClassificationMethod)
CEF.sens$ClassificationMethod <- gsub("MDA", "M", CEF.sens$ClassificationMethod)
CEF.sens$ClassificationMethod <- gsub("FDA", "F", CEF.sens$ClassificationMethod)
CEF.sens$ClassificationMethod <- gsub("Tree", "T", CEF.sens$ClassificationMethod)
CEF.sens$ClassificationMethod <- gsub("RF", "R", CEF.sens$ClassificationMethod)
CEF.sens$ClassificationMethod <- factor(CEF.sens$ClassificationMethod, levels = c("L","Q","M","F","G","T","R"))

CEF.sens %>% ggplot() + aes(x = EmbeddingMethod, y=CEF.means, color = ClassificationMethod) + 
  geom_text(aes(label = ClassificationMethod)) +
  facet_wrap(~FilterMinAppear_F, ncol = 2)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  scale_color_manual(values = colrs.class)+
  xlab("Embedding Method") +
  ylab("Sensitivity Rate")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")
```

(ref:stopClassVi-sens) $C \times S$, F-ratio = `r round(df.ano.sens$Frat[8],3)`. The effect of filtering stop words by classification method on sensitivity. The median is a black triangle, and the mean is a grey circle.

```{r stopClassVi-sens, echo = FALSE, tidy  = TRUE,warning=FALSE, fig.cap="(ref:stopClassVi-sens)", fig.height=7, fig.align='center', cache=TRUE}
data.filter %>% ggplot(aes(x = FilterStopwords, y = Sensitivity, fill = FilterStopwords)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~ClassificationMethod, ncol=2)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  xlab("Filter Stop Words?") +
  ylab("Sensitivity Rate")+
  theme_bw()+
  theme(legend.position = "none")
```

(ref:numClassVi-sens) $C \times N$, F-ratio = `r round(df.ano.sens$Frat[12],3)`. The effect of filtering numbers by classification method on sensitivity. The median is a black triangle, and the mean is a grey circle.

```{r numClassVi-sens, echo = FALSE, tidy  = TRUE,warning=FALSE,fig.cap="(ref:numClassVi-sens)", fig.height=7, fig.align='center', cache=TRUE}
data.filter %>% ggplot(aes(x = FilterNumbers, y = Sensitivity, fill = FilterNumbers)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~ClassificationMethod, ncol=2)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  xlab("Filter Numbers?") +
  ylab("Sensitivity Rate")+
  theme_bw()+
  theme(legend.position = "none")
```

(ref:minClassVi-sens) $C \times F$, F-ratio = `r round(df.ano.sens$Frat[14],3)`. The effect of filtering threshold by classification method on sensitivity. The median is a black triangle, and the mean is a grey circle.

```{r minClassVi-sens, echo = FALSE, tidy  = TRUE,warning=FALSE,fig.cap="(ref:minClassVi-sens)", fig.height=7, fig.align='center', cache=TRUE}
data.filter %>% ggplot(aes(x = FilterMinAppear_F, y = Sensitivity, fill = FilterMinAppear_F)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~ClassificationMethod, ncol=2)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  xlab("Minimum Number of Appearances") +
  ylab("Sensitivity Rate")+
  theme_bw()+
  theme(legend.position = "none")
```

(ref:minEmbVi-sens) $E \times F$, F-ratio = `r round(df.ano.sens$Frat[15],5)`. The effect of filtering threshold by embedding method on sensitivity. The median is a black triangle, and the mean is a grey circle.

```{r minEmbVi-sens, echo = FALSE, tidy  = TRUE,warning=FALSE,fig.cap="(ref:minEmbVi-sens)", fig.height=7, fig.align='center', cache=TRUE}
data.filter %>% 
  ggplot(aes(x = FilterMinAppear_F, y = Sensitivity, fill = FilterMinAppear_F)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~EmbeddingMethod, ncol=4)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  xlab("Minimum Number of Appearances") +
  ylab("Sensitivity Rate")+
  theme_bw()+
  theme(legend.position = "none")
```

(ref:ClassEmbVi-sens) $C \times E$, F-ratio = `r round(df.ano.sens$Frat[7],3)`. The effect of classification method by embedding method on sensitivity. Discriminant analyses are in blue. Logistic regression is red, and tree-based methods are in green. The median is a black triangle, and the mean is a grey circle.

```{r ClassEmbVi-sens, echo = FALSE, tidy  = TRUE,warning=FALSE,fig.cap="(ref:ClassEmbVi-sens)", fig.height=7, fig.align='center', cache=TRUE}
data.filter %>% 
  ggplot(aes(x = ClassificationMethod, y = Sensitivity, fill = ClassificationMethod)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~EmbeddingMethod, ncol=4)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  scale_fill_manual(values = colrs.class) +
  xlab("Embedding Method") +
  ylab("Sensitivity Rate")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")
```

(ref:sens-Class) $C$, F-ratio = `r round(df.ano.sens$Frat[1],3)`. The effect of classification method on sensitivity. Discriminant analyses are in blue. Logistic regression is red, and tree-based methods are in green. The median is a black triangle, and the mean is a grey circle.

```{r sens-Class, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE,fig.cap="(ref:sens-Class)",  fig.align='center', cache=TRUE}
data.filter %>% 
  ggplot(aes(x = ClassificationMethod, y = Sensitivity, fill = ClassificationMethod)) +
  geom_violin(trim=FALSE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  scale_fill_manual(values = colrs.class)+
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Classification Method") +
  ylab("Sensitivity Rate")
```

(ref:sens-Emb) $E$, F-ratio = `r round(df.ano.sens$Frat[2],3)`. The effect of embedding method on sensitivity. Word2Vec Continuous Bag of Words are in the blue-green shades, and Word2Vec Skip-Gram are in the blue-purple shades. GloVe is in the brown-orange shades. BERT is in pink, and PCA is in green. The median is a black triangle, and the mean is a grey circle.

```{r sens-Emb, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE,fig.cap="(ref:sens-Emb)",  fig.align='center', cache=TRUE}
data.filter %>% 
  ggplot(aes(x = EmbeddingMethod, y = Sensitivity, fill = EmbeddingMethod)) +
  geom_violin(trim=FALSE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  scale_fill_manual(values = colrs.emb)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")+
  xlab("Embedding Method") +
  ylab("Sensitivity Rate")
```

(ref:sens-Stop) $S$, F-ratio = `r round(df.ano.sens$Frat[3],3)`. The effect of filtering stop words on sensitivity. The median is a black triangle, and the mean is a grey circle.

```{r sens-Stop, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE,fig.cap="(ref:sens-Stop)",  fig.align='center', cache=TRUE}
data.filter %>% 
  ggplot(aes(x = FilterStopwords, y = Sensitivity, fill = FilterStopwords)) +
  geom_violin(trim=FALSE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Filter Stop Words?") +
  ylab("Sensitivity Rate")
```

(ref:sens-Low) $L$, F-ratio = `r round(df.ano.sens$Frat[4],3)`. The effect of converting to lowercase on sensitivity. The median is a black triangle, and the mean is a grey circle.

```{r sens-Low, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE,fig.cap="(ref:sens-Low)",  fig.align='center', cache=TRUE}
data.filter %>% 
  ggplot(aes(x = ConvertLower, y = Sensitivity, fill = ConvertLower)) +
  geom_violin(trim=FALSE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Convert to Lowercase?") +
  ylab("Sensitivity Rate")
```

(ref:sens-Num) $N$, F-ratio = `r round(df.ano.sens$Frat[5],3)`. The effect of filtering numbers on sensitivity. The median is a black triangle, and the mean is a grey circle.

```{r sens-Num, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE,fig.cap="(ref:sens-Num)",  fig.align='center', cache=TRUE}
data.filter %>% 
  ggplot(aes(x = FilterNumbers, y = Sensitivity, fill = FilterNumbers)) +
  geom_violin(trim=FALSE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Filter Numbers?") +
  ylab("Sensitivity Rate")
```

(ref:sens-Min) $F$, F-ratio = `r round(df.ano.sens$Frat[6],3)`. The effect of filtering threshold on sensitivity. The median is a black triangle, and the mean is a grey circle.

```{r sens-Min, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE,fig.cap="(ref:sens-Min)",  fig.align='center', cache=TRUE}
data.filter %>% 
  ggplot(aes(x = FilterMinAppear_F, y = Sensitivity, fill = FilterMinAppear_F)) +
  geom_violin(trim=FALSE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Minimum Number of Appearances") +
  ylab("Sensitivity Rate")
```

(ref:spec-FC) $C \times E \times F$, F-ratio = `r round(df.ano.spec$Frat[19],3)`. The effect of classification method, embedding method, and filtering threshold on specificity. Each classification method is represented by a letter. T is for classification tree, and G is for logistic regression. All others are based on the first letter of the method name. Only the means are plotted here. Violin plots are not used due to the number of levels of filtering threshold.

```{r spec-FC, echo=FALSE, message=FALSE,warning=FALSE,tidy=TRUE,fig.cap="(ref:spec-FC)", fig.align='center', cache=TRUE}
CEF.spec$ClassificationMethod <- gsub("LogReg", "G", CEF.spec$ClassificationMethod)
CEF.spec$ClassificationMethod <- gsub("LDA", "L", CEF.spec$ClassificationMethod)
CEF.spec$ClassificationMethod <- gsub("QDA", "Q", CEF.spec$ClassificationMethod)
CEF.spec$ClassificationMethod <- gsub("MDA", "M", CEF.spec$ClassificationMethod)
CEF.spec$ClassificationMethod <- gsub("FDA", "F", CEF.spec$ClassificationMethod)
CEF.spec$ClassificationMethod <- gsub("Tree", "T", CEF.spec$ClassificationMethod)
CEF.spec$ClassificationMethod <- gsub("RF", "R", CEF.spec$ClassificationMethod)
CEF.spec$ClassificationMethod <- factor(CEF.spec$ClassificationMethod, levels = c("L","Q","M","F","G","T","R"))

CEF.spec %>% ggplot() + aes(x = EmbeddingMethod, y=CEF.means, color = ClassificationMethod) + 
  geom_text(aes(label = ClassificationMethod)) +
  facet_wrap(~FilterMinAppear_F, ncol = 2)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  scale_color_manual(values = colrs.class)+
  xlab("Embedding Method") +
  ylab("Specificity Rate")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")
```

(ref:stopClassVi-spec) $C \times S$, F-ratio = `r round(df.ano.spec$Frat[8],3)`. The effect of filtering stop words by classification method on specificity. The median is a black triangle, and the mean is a grey circle.

```{r stopClassVi-spec, echo = FALSE, tidy  = TRUE,warning=FALSE, fig.cap="(ref:stopClassVi-spec)", fig.height=7, fig.align='center', cache=TRUE}
data.filter %>% 
  ggplot(aes(x = FilterStopwords, y = Specificity, fill = FilterStopwords)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~ClassificationMethod, ncol=2)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  xlab("Filter Stop Words?") +
  ylab("Specificity Rate")+
  theme_bw()+
  theme(legend.position = "none")
```

(ref:stopEmbVi-spec) $E \times S$, F-ratio = `r round(df.ano.spec$Frat[9],3)`. The effect of filtering stop words by embedding method on specificity. The median is a black triangle, and the mean is a grey circle.

```{r stopEmbVi-spec, echo = FALSE, tidy  = TRUE,warning=FALSE,fig.cap="(ref:stopEmbVi-spec)", fig.height=7, fig.align='center', cache=TRUE}
data.filter %>% 
  ggplot(aes(x = FilterStopwords, y = Specificity, fill = FilterStopwords)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~EmbeddingMethod, ncol=4)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  xlab("Filter Stop Words?") +
  ylab("Specificity Rate")+
  theme_bw()+
  theme(legend.position = 'none') 
```

(ref:numClassVi-spec) $C \times N$, F-ratio = `r round(df.ano.spec$Frat[12],3)`. The effect of filtering numbers by classification method on specificity. The median is a black triangle, and the mean is a grey circle.

```{r numClassVi-spec, echo = FALSE, tidy  = TRUE,warning=FALSE,fig.cap="(ref:numClassVi-spec)", fig.height=7, fig.align='center', cache=TRUE}
data.filter %>% 
  ggplot(aes(x = FilterNumbers, y = Specificity, fill = FilterNumbers)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~ClassificationMethod, ncol=2)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  xlab("Filter Numbers?") +
  ylab("Specificity Rate")+
  theme_bw()+
  theme(legend.position = "none")
```

(ref:numEmbVi-spec) $E \times N$, F-ratio = `r round(df.ano.spec$Frat[13],3)`. The effect of filtering numbers by embedding method on specificity. The median is a black triangle, and the mean is a grey circle.

```{r numEmbVi-spec, echo = FALSE, tidy  = TRUE,warning=FALSE,fig.cap="(ref:numEmbVi-spec)", fig.height=7, fig.align='center', cache=TRUE}
data.filter %>% 
  ggplot(aes(x = FilterNumbers, y = Specificity, fill = FilterNumbers)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~EmbeddingMethod, ncol=4)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  xlab("Filter Numbers?") +
  ylab("Specificity Rate")+
  theme_bw()+
  theme(legend.position = "none")
```

(ref:minClassVi-spec) $C \times F$, F-ratio = `r round(df.ano.spec$Frat[14],3)`. The effect of filtering threshold by classification method on specificity. The median is a black triangle, and the mean is a grey circle.

```{r minClassVi-spec, echo = FALSE, tidy  = TRUE,warning=FALSE,fig.cap="(ref:minClassVi-spec)", fig.height=7, fig.align='center', cache=TRUE}
data.filter %>% 
  ggplot(aes(x = FilterMinAppear_F, y = Specificity, fill = FilterMinAppear_F)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~ClassificationMethod, ncol=2)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  xlab("Minimum Number of Appearances") +
  ylab("Specificity Rate")+
  theme_bw()+
  theme(legend.position = "none")
```

(ref:minEmbVi-spec) $E \times F$, F-ratio = `r round(df.ano.spec$Frat[15],3)`. The effect of filtering threshold by embedding method on specificity. The median is a black triangle, and the mean is a grey circle.

```{r minEmbVi-spec, echo = FALSE, tidy  = TRUE,warning=FALSE,fig.cap="(ref:minEmbVi-spec)", fig.height=7, fig.align='center', cache=TRUE}
data.filter %>% 
  ggplot(aes(x = FilterMinAppear_F, y = Specificity, fill = FilterMinAppear_F)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~EmbeddingMethod, ncol=4)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  xlab("Minimum Number of Appearances") +
  ylab("Specificity Rate")+
  theme_bw()+
  theme(legend.position = "none")
```

(ref:ClassEmbVi-spec) $C \times E$, F-ratio = `r round(df.ano.spec$Frat[7],3)`. The effect of embedding method by classification method on specificity. Discriminant analyses are in blue. Logistic regression is red, and tree-based methods are in green. The median is a black triangle, and the mean is a grey circle.

```{r ClassEmbVi-spec, echo = FALSE, tidy  = TRUE,warning=FALSE,fig.cap="(ref:ClassEmbVi-spec)", fig.height=7, fig.align='center', cache=TRUE}
data.filter %>% 
  ggplot(aes(x = ClassificationMethod, y = Specificity, fill = ClassificationMethod)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~EmbeddingMethod, ncol=4)+
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  scale_fill_manual(values = colrs.class) +
  xlab("Embedding Method") +
  ylab("Mean Specificity Rate")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")
```

(ref:spec-Class) $C$, F-ratio = `r round(df.ano.spec$Frat[1],3)`. The effect of classification method on specificity. Discriminant analyses are in blue. Logistic regression is red, and tree-based methods are in green. The median is a black triangle, and the mean is a grey circle.

```{r spec-Class, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE,fig.cap="(ref:spec-Class)",  fig.align='center', cache=TRUE}
data.filter %>% 
  ggplot(aes(x = ClassificationMethod, y = Specificity, fill = ClassificationMethod)) +
  geom_violin(trim=FALSE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  scale_fill_manual(values = colrs.class)+
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Classification Method") +
  ylab("Specificity Rate")
```

(ref:spec-Emb) $E$, F-ratio = `r round(df.ano.spec$Frat[2],3)`. The effect of embedding method on specificity. Word2Vec Continuous Bag of Words are in the blue-green shades, and Word2Vec Skip-Gram are in the blue-purple shades. GloVe is in the brown-orange shades. BERT is in pink, and PCA is in green. The median is a black triangle, and the mean is a grey circle.

```{r spec-Emb, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE,fig.cap="(ref:spec-Emb)",  fig.align='center', cache=TRUE}
data.filter %>% 
  ggplot(aes(x = EmbeddingMethod, y = Specificity, fill = EmbeddingMethod)) +
  geom_violin(trim=FALSE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  scale_fill_manual(values = colrs.emb)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")+
  xlab("Embedding Method") +
  ylab("Specificity Rate")
```

(ref:spec-Low) $L$, F-ratio = `r round(df.ano.spec$Frat[4],3)`. The effect of converting to lowercase on specificity. The median is a black triangle, and the mean is a grey circle.

```{r spec-Low, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE, fig.cap="(ref:spec-Low)", fig.align='center', cache=TRUE}
data.filter %>% 
  ggplot(aes(x = ConvertLower, y = Specificity, fill = ConvertLower)) +
  geom_violin(trim=FALSE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Convert to Lowercase?") +
  ylab("Specificity Rate")
```

(ref:spec-Num) $N$, F-ratio = `r round(df.ano.spec$Frat[5],3)`. The effect of filtering numbers on specificity. The median is a black triangle, and the mean is a grey circle.

```{r spec-Num, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE,fig.cap="(ref:spec-Num)",  fig.align='center', cache=TRUE}
data.filter %>% 
  ggplot(aes(x = FilterNumbers, y = Specificity, fill = FilterNumbers)) +
  geom_violin(trim=FALSE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Filter Numbers?") +
  ylab("Specificity Rate")
```

(ref:spec-Min) $F$, F-ratio = `r round(df.ano.spec$Frat[6],3)`. The effect of filtering threshold on specificity. The median is a black triangle, and the mean is a grey circle.

```{r spec-Min, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE,fig.cap="(ref:spec-Min)",  fig.align='center', cache=TRUE}
data.filter %>% 
  ggplot(aes(x = FilterMinAppear_F, y = Specificity, fill = FilterMinAppear_F)) +
  geom_violin(trim=FALSE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.5, linetype = 'dashed', size =1)+
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Minimum Number of Appearances") +
  ylab("Specificity Rate")
```

# Plots for Chapter \@ref(MultiClass)

This appendix contains all interaction and main effect mean plots discussed in Chapter \@ref(MultiClass) for effects with a F-ratio greater than 2. It also contains appropriate violin plots for the main effect and two-way interactions allowing us to visualize the distribution of observations.

(ref:overacc-CES) $C \times E \times S$,  F-ratio = `r round(df.ano.acc.multi$Frat[13],3)`. The difference in overall accuracy between filtering of stop words (no-yes) for each combination of classification and embedding method. Discriminant analyses are in blue. Logistic regression is red, and tree-based methods are in green. The median is a black triangle, and the mean is a grey circle.

```{r overacc-CES, echo=FALSE, message=FALSE,warning=FALSE,tidy=TRUE,fig.cap="(ref:overacc-CES)", fig.height=7, fig.align='center', cache=TRUE}
CES.multi <- data.multi.filter %>% 
  group_by(ClassificationMethod,EmbeddingMethod,FilterStopwords) %>% 
  select(ClassificationMethod, EmbeddingMethod, FilterStopwords, OverallAccuracy)
CES.multi.no <- CES.multi %>% subset(FilterStopwords == "No")
CES.multi.yes <- CES.multi %>% subset(FilterStopwords == "Yes")
CES.multi.no$CES.acc.yes <- CES.multi.yes$OverallAccuracy
CES.multi.new <- CES.multi.no %>% summarize(CES.diff = OverallAccuracy - CES.acc.yes)

CES.multi.new %>% 
  ggplot(aes(x = ClassificationMethod, y = CES.diff, fill = ClassificationMethod)) +
  geom_violin(trim=FALSE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~EmbeddingMethod,ncol = 4)+
  geom_hline(yintercept = 0, linetype = 'dashed', linewidth =1)+
  scale_fill_manual(values = colrs.class)+
  xlab("Classification Method") +
  ylab("Overall Accuracy Rate")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),legend.position = "none")
```

(ref:ClassYearVi-OverAcc) $C \times R$,  F-ratio = `r round(df.ano.acc.multi$Frat[11],3)`. The effect of including year as a predictor by classification method on the overall accuracy. The median is a black triangle, and the mean is a grey circle.

```{r ClassYearVi-OverAcc, echo = FALSE, tidy  = TRUE,warning=FALSE, fig.cap="(ref:ClassYearVi-OverAcc)", fig.height=7, fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = YearIncluded, y = OverallAccuracy, fill = YearIncluded)) +
  geom_violin(trim=TRUE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~ClassificationMethod,ncol=2)+
  geom_hline(yintercept = 0.21, linetype = 'dashed', linewidth =1)+
  xlab("Include Year?") +
  ylab("Overall Accuracy Rate")+
  theme_bw()+
  theme(legend.position = "none")
```

(ref:ClassMinVi-OverAcc) $C \times F$,  F-ratio = `r round(df.ano.acc.multi$Frat[9],3)`. The effect of filtering threshold by classification method on the overall accuracy. The median is a black triangle, and the mean is a grey circle.

```{r ClassMinVi-OverAcc, echo = FALSE, tidy  = TRUE,warning=FALSE, fig.cap="(ref:ClassMinVi-OverAcc)", fig.height=7, fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = FilterMinAppear_F, y = OverallAccuracy, fill = FilterMinAppear_F)) +
  geom_violin(trim=TRUE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~ClassificationMethod,ncol=2)+
  geom_hline(yintercept = 0.21, linetype = 'dashed', linewidth =1)+
  xlab("Minimum Number of Appearances") +
  ylab("Overall Accuracy Rate")+
  theme_bw()+
  theme(legend.position = "none")
```

(ref:EmbMinVi-overacc) $E \times F$,  F-ratio = `r round(df.ano.acc.multi$Frat[10],3)`. The effect of filtering threshold by embedding method on the overall accuracy. The median is a black triangle, and the mean is a grey circle.

```{r EmbMinVi-overacc, echo = FALSE, tidy  = TRUE,warning=FALSE, fig.cap="(ref:EmbMinVi-overacc)", fig.height=7, fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = FilterMinAppear_F, y = OverallAccuracy, fill = FilterMinAppear_F)) +
  geom_violin(trim=TRUE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~EmbeddingMethod, ncol=4)+
  geom_hline(yintercept = 0.21, linetype = 'dashed', size =1)+
  xlab("Minimum Number of Appearances") +
  ylab("Overall Accuracy Rate")+
  theme_bw()+
  theme(legend.position = "none")
```

(ref:ClassStopVi-OverAcc) $C \times S$,  F-ratio = `r round(df.ano.acc.multi$Frat[7],3)`. The effect of filtering stop words by classification method on the overall accuracy. The median is a black triangle, and the mean is a grey circle.

```{r ClassStopVi-OverAcc, echo = FALSE, tidy  = TRUE,warning=FALSE, fig.cap="(ref:ClassStopVi-OverAcc)", fig.height=7, fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = FilterStopwords, y = OverallAccuracy, fill = FilterStopwords)) +
  geom_violin(trim=TRUE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~ClassificationMethod,ncol=2)+
  geom_hline(yintercept = 0.21, linetype = 'dashed', size =1)+
  xlab("Filter Stop Words?") +
  ylab("Overall Accuracy Rate")+
  theme_bw()+
  theme(legend.position = "none")
```

(ref:ClassEmbVi-OverAcc) $C \times E$,  F-ratio = `r round(df.ano.acc.multi$Frat[6],3)`. The effect of classification method by embedding method on the overall accuracy. Discriminant analyses are in blue. Logistic regression is red, and tree-based methods are in green. The median is a black triangle, and the mean is a grey circle.

```{r ClassEmbVi-OverAcc, echo = FALSE, tidy  = TRUE, warning=FALSE,fig.cap="(ref:ClassEmbVi-OverAcc)", fig.height=7, fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = ClassificationMethod, y = OverallAccuracy, fill = ClassificationMethod)) +
  geom_violin(trim=TRUE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~EmbeddingMethod, ncol=4)+
  geom_hline(yintercept = 0.21, linetype = 'dashed', size =1)+
  scale_fill_manual(values = colrs.class) +
  xlab("Embedding Method") +
  ylab("Overall Accuracy Rate")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")
```

(ref:overacc-Year) $R$,  F-ratio = `r round(df.ano.acc.multi$Frat[5],3)`. The effect of including year as a predictor on the overall accuracy. The median is a black triangle, and the mean is a grey circle.

```{r overacc-Year, echo=FALSE,warning=FALSE, message=FALSE, tidy=TRUE,fig.cap="(ref:overacc-Year)",fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = YearIncluded, y = OverallAccuracy, fill = YearIncluded)) +
  geom_violin(trim=TRUE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.21, linetype = 'dashed', size =1)+
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Included Year?") +
  ylab("Overall Accuracy Rate")
```

(ref:overacc-Min) $F$,  F-ratio = `r round(df.ano.acc.multi$Frat[4],3)`. The effect of filtering threshold on the overall accuracy. The median is a black triangle, and the mean is a grey circle.

```{r overacc-Min, echo=FALSE,warning=FALSE, message=FALSE, tidy=TRUE, fig.cap="(ref:overacc-Min)", fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = FilterMinAppear_F, y = OverallAccuracy, fill = FilterMinAppear_F)) +
  geom_violin(trim=TRUE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.21, linetype = 'dashed', size =1)+
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Minimum Number of Appearances") +
  ylab("Overall Accuracy Rate")
```

(ref:overacc-Stop) $S$,  F-ratio = `r round(df.ano.acc.multi$Frat[3],3)`. The effect of filtering stop words on the overall accuracy. The median is a black triangle, and the mean is a grey circle.

```{r overacc-Stop, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE, fig.cap="(ref:overacc-Stop)", fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = FilterStopwords, y = OverallAccuracy, fill = FilterStopwords)) +
  geom_violin(trim=TRUE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.21, linetype = 'dashed', size =1)+
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Filter Stop Words?") +
  ylab("Overall Accuracy Rate")
```

(ref:overacc-Emb) $E$, F-ratio = `r round(df.ano.acc.multi$Frat[2],3)`. The effect of embedding method on overall accuracy. Word2Vec Continuous Bag of Words are in the blue-green shades, and Word2Vec Skip-Gram are in the blue-purple shades. GloVe is in the brown-orange shades. BERT is in pink, and PCA is in green. The median is a black triangle, and the mean is a grey circle.

```{r overacc-Emb, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE, fig.cap="(ref:overacc-Emb)",  fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = EmbeddingMethod, y = OverallAccuracy, fill = EmbeddingMethod)) +
  geom_violin(trim=TRUE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.21, linetype = 'dashed', size =1)+
  scale_fill_manual(values = colrs.emb)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")+
  xlab("Embedding Method") +
  ylab("Overall Accuracy Rate")
```

(ref:overacc-Class) $C$, F-ratio = `r round(df.ano.acc.multi$Frat[1],3)`. The effect of classification method on overall accuracy. Discriminant analyses are in blue. Logistic regression is red, and tree-based methods are in green. The median is a black triangle, and the mean is a grey circle.

```{r overacc-Class, echo=FALSE,warning=FALSE, message=FALSE, tidy=TRUE, fig.cap="(ref:overacc-Class)", fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = ClassificationMethod, y = OverallAccuracy, fill = ClassificationMethod)) +
  geom_violin(trim=TRUE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.21, linetype = 'dashed', size =1)+
  scale_fill_manual(values = colrs.class)+
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Classification Method") +
  ylab("Overall Accuracy Rate")
```

(ref:ClassYearVi-senstrue) $C \times R$,  F-ratio = `r round(df.ano.sens.true.multi$Frat[11],3)`. The effect of including year as a predictor by classification method on the sensitivity of a true label. The median is a black triangle, and the mean is a grey circle.

```{r ClassYearVi-senstrue, echo = FALSE, tidy  = TRUE,warning=FALSE, fig.cap="(ref:ClassYearVi-senstrue)", fig.height=7, fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = YearIncluded, y = Sensitivity_True, fill = YearIncluded)) +
  geom_violin(trim=TRUE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~ClassificationMethod,ncol=2)+
  geom_hline(yintercept = 0.14, linetype = 'dashed', size =1)+
  xlab("Include Year?") +
  ylab("Sensitivity Rate")+
  theme_bw()+
  theme(legend.position = "none") 
```

(ref:ClassMinVi-senstrue) $C \times F$,  F-ratio = `r round(df.ano.sens.true.multi$Frat[9],3)`. The effect of filtering threshold by classification method on the sensitivity of a true label. The median is a black triangle, and the mean is a grey circle.

```{r ClassMinVi-senstrue, echo = FALSE, tidy  = TRUE,warning=FALSE, fig.cap="(ref:ClassMinVi-senstrue)", fig.height=7, fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = FilterMinAppear_F, y = Sensitivity_True, fill = FilterMinAppear_F)) +
  geom_violin(trim=TRUE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~ClassificationMethod,ncol=2)+
  geom_hline(yintercept = 0.14, linetype = 'dashed', size =1)+
  xlab("Minimum Appearances") +
  ylab("Sensitivity Rate")+
  theme_bw()+
  theme(legend.position = "none") 
```

(ref:ClassStopVi-senstrue) $C \times S$,  F-ratio = `r round(df.ano.sens.true.multi$Frat[7],3)`. The effect of filtering stop words by classification method on the sensitivity of a true label. The median is a black triangle, and the mean is a grey circle.

```{r ClassStopVi-senstrue, echo = FALSE, tidy  = TRUE,warning=FALSE, fig.cap="(ref:ClassStopVi-senstrue)", fig.height=7, fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = FilterStopwords, y = Sensitivity_True, fill = FilterStopwords)) +
  geom_violin(trim=TRUE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~ClassificationMethod,ncol=2)+
  geom_hline(yintercept = 0.14, linetype = 'dashed', size =1)+
  xlab("Filter Stop Words?") +
  ylab("Sensitivity Rate")+
  theme_bw()+
  theme(legend.position = "none") 
```

(ref:ClassEmbVi-senstrue) $C \times E$,  F-ratio = `r round(df.ano.sens.true.multi$Frat[6],3)`. The effect of classification method by embedding method on the sensitivity of a true label. Discriminant analyses are in blue. Logistic regression is red, and tree-based methods are in green. The median is a black triangle, and the mean is a grey circle.

```{r ClassEmbVi-senstrue, echo = FALSE, tidy  = TRUE, warning=FALSE, fig.cap="(ref:ClassEmbVi-senstrue)", fig.height=7, fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = ClassificationMethod, y = Sensitivity_True, fill = ClassificationMethod)) +
  geom_violin(trim=TRUE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~EmbeddingMethod, ncol=4)+
  geom_hline(yintercept = 0.14, linetype = 'dashed', size =1)+
  scale_fill_manual(values = colrs.class) +
  xlab("Embedding Method") +
  ylab("Sensitivity Rate")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")
```

(ref:senstrue-Min) $F$,  F-ratio = `r round(df.ano.sens.true.multi$Frat[4],3)`. The effect of filtering threshold on the sensitivity of a true label. The median is a black triangle, and the mean is a grey circle.

```{r senstrue-Min, echo=FALSE,warning=FALSE, message=FALSE, tidy=TRUE, fig.cap="(ref:senstrue-Min)", fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = FilterMinAppear_F, y = Sensitivity_True, fill = FilterMinAppear_F)) +
  geom_violin(trim=TRUE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.14, linetype = 'dashed', size =1)+
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Minimum Number of Appearances") +
  ylab("Sensitivity Rate")
```

(ref:senstrue-Emb) $E$, F-ratio = `r round(df.ano.sens.true.multi$Frat[2],3)`. The effect of embedding method on the sensitivity of a true label. Word2Vec Continuous Bag of Words are in the blue-green shades, and Word2Vec Skip-Gram are in the blue-purple shades. GloVe is in the brown-orange shades. BERT is in pink, and PCA is in green. The median is a black triangle, and the mean is a grey circle.

```{r senstrue-Emb, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE, fig.cap="(ref:senstrue-Emb)", fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = EmbeddingMethod, y = Sensitivity_True, fill = EmbeddingMethod)) +
  geom_violin(trim=TRUE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.14, linetype = 'dashed', size =1)+
  scale_fill_manual(values = colrs.emb)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")+
  xlab("Embedding Method") +
  ylab("Sensitivity Rate")
```

(ref:senstrue-Class) $C$, F-ratio = `r round(df.ano.sens.true.multi$Frat[1],3)`. The effect of classification method on the sensitivity of a true label. Discriminant analyses are in blue. Logistic regression is red, and tree-based methods are in green. The median is a black triangle, and the mean is a grey circle.

```{r senstrue-Class, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE, fig.cap="(ref:senstrue-Class)",fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = ClassificationMethod, y = Sensitivity_True, fill = ClassificationMethod)) +
  geom_violin(trim=TRUE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.14, linetype = 'dashed', size =1)+
  scale_fill_manual(values = colrs.class)+
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Classification Method") +
  ylab("Sensitivity Rate")
```

(ref:ClassYearVi-spectrue) $C \times R$,  F-ratio = `r round(df.ano.spec.true.multi$Frat[11],3)`. The effect of including year as a predictor by classification method on the specificity of a true label. The median is a black triangle, and the mean is a grey circle.

```{r ClassYearVi-spectrue, echo = FALSE, tidy  = TRUE,warning=FALSE, fig.cap="(ref:ClassYearVi-spectrue)", fig.height=7, fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = YearIncluded, y = Specificity_True, fill = YearIncluded)) +
  geom_violin(trim=TRUE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~ClassificationMethod,ncol=2)+
  xlab("Include Year?") +
  ylab("Specificity Rate")+
  theme_bw()+
  theme(legend.position = "none") 
```

(ref:ClassMinVi-spectrue) $C \times F$,  F-ratio = `r round(df.ano.spec.true.multi$Frat[9],3)`. The effect of filtering threshold by classification method on the specificity of a true label. The median is a black triangle, and the mean is a grey circle.

```{r ClassMinVi-spectrue, echo = FALSE, tidy  = TRUE,warning=FALSE, fig.cap="(ref:ClassMinVi-spectrue)", fig.height=7, fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = FilterMinAppear_F, y = Specificity_True, fill = FilterMinAppear_F)) +
  geom_violin(trim=TRUE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~ClassificationMethod,ncol=2)+
  xlab("Minimum Number of Appearances") +
  ylab("Specificity Rate")+
  theme_bw()+
  theme(legend.position = "none") 
```

(ref:ClassStopVi-spectrue) $C \times S$,  F-ratio = `r round(df.ano.spec.true.multi$Frat[7],3)`. The effect of filtering stop words by classification method on the specificity of a true label. The median is a black triangle, and the mean is a grey circle.

```{r ClassStopVi-spectrue, echo = FALSE, tidy  = TRUE,warning=FALSE, fig.cap="(ref:ClassStopVi-spectrue)", fig.height=7, fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = FilterStopwords, y = Specificity_True, fill = FilterStopwords)) +
  geom_violin(trim=TRUE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~ClassificationMethod,ncol=2)+
  xlab("Filter Stop Words?") +
  ylab("Specificity Rate")+
  theme_bw()+
  theme(legend.position = "none") 
```

(ref:ClassEmbVi-spectrue) $C \times E$,  F-ratio = `r round(df.ano.spec.true.multi$Frat[6],3)`. The effect of classification method by embedding method on the specificity of a true label. Discriminant analyses are in blue. Logistic regression is red, and tree-based methods are in green. The median is a black triangle, and the mean is a grey circle.

```{r ClassEmbVi-spectrue, echo = FALSE, tidy  = TRUE, warning=FALSE, fig.cap="(ref:ClassEmbVi-spectrue)", fig.height=7, fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = ClassificationMethod, y = Specificity_True, fill = ClassificationMethod)) +
  geom_violin(trim=TRUE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~EmbeddingMethod, ncol=4)+
  scale_fill_manual(values = colrs.class) +
  xlab("Embedding Method") +
  ylab("Specificity Rate")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")
```

(ref:spectrue-Year) $R$,  F-ratio = `r round(df.ano.spec.true.multi$Frat[5],3)`. The effect of including year as a predictor on the specificity of a true label. The median is a black triangle, and the mean is a grey circle.

```{r spectrue-Year, echo=FALSE,warning=FALSE, message=FALSE, tidy=TRUE, fig.cap="(ref:spectrue-Year)", fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = YearIncluded, y = Specificity_True, fill = YearIncluded)) +
  geom_violin(trim=TRUE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Include Year?") +
  ylab("Specificity Rate")
```

(ref:spectrue-Min) $F$,  F-ratio = `r round(df.ano.spec.true.multi$Frat[4],3)`. The effect of filtering threshold on the specificity of a true label. The median is a black triangle, and the mean is a grey circle.

```{r spectrue-Min, echo=FALSE,warning=FALSE, message=FALSE, tidy=TRUE, fig.cap="(ref:spectrue-Min)", fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = FilterMinAppear_F, y = Specificity_True, fill = FilterMinAppear_F)) +
  geom_violin(trim=TRUE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Minimum Number of Appearances") +
  ylab("Specificity Rate")
```

(ref:spectrue-Stop) $S$,  F-ratio = `r round(df.ano.spec.true.multi$Frat[3],3)`. The effect of filtering stop words on the specificity of a true label. The median is a black triangle, and the mean is a grey circle.

```{r spectrue-Stop, echo=FALSE,warning=FALSE, message=FALSE, tidy=TRUE, fig.cap="(ref:spectrue-Stop)", fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = FilterStopwords, y = Specificity_True, fill = FilterStopwords)) +
  geom_violin(trim=TRUE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Filter Stop Words?") +
  ylab("Specificity Rate")
```

(ref:spectrue-Emb) $E$, F-ratio = `r round(df.ano.spec.true.multi$Frat[2],3)`. The effect of embedding method on the specificity of a true label. Word2Vec Continuous Bag of Words are in the blue-green shades, and Word2Vec Skip-Gram are in the blue-purple shades. GloVe is in the brown-orange shades. BERT is in pink, and PCA is in green. The median is a black triangle, and the mean is a grey circle.

```{r spectrue-Emb, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE, fig.cap="(ref:spectrue-Emb)", fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = EmbeddingMethod, y = Specificity_True, fill = EmbeddingMethod)) +
  geom_violin(trim=TRUE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  scale_fill_manual(values = colrs.emb)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")+
  xlab("Embedding Method") +
  ylab("Specificity Rate")
```

(ref:spectrue-Class) $C$, F-ratio = `r round(df.ano.spec.true.multi$Frat[1],3)`. The effect of classification method on the specificity of a true label. Discriminant analyses are in blue. Logistic regression is red, and tree-based methods are in green. The median is a black triangle, and the mean is a grey circle.

```{r spectrue-Class, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE, fig.cap="(ref:spectrue-Class)", fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = ClassificationMethod, y = Specificity_True, fill = ClassificationMethod)) +
  geom_violin(trim=TRUE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  scale_fill_manual(values = colrs.class)+
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Classification Method") +
  ylab("Specificity Rate")
```

(ref:senspf-CER) $C \times E \times R$, F-ratio = `r round(df.ano.sens.pf.multi$Frat[15],3)`. The effect of classification method, embedding method, and inclusion of year as a predictor on the sensitivity of a pants-on-fire label. Only the means are plotted here. Violin plots are not used due to the unbalanced number of combinations between the levels since there were computational issues. There are fewer combinations observed when year is included as a predictor.

```{r senspf-CER, echo=FALSE, message=FALSE,warning=FALSE,tidy=TRUE,fig.cap="(ref:senspf-CER)", fig.height=7, fig.align='center', cache=TRUE}
CER.sens.pf %>% 
  ggplot() + aes(x = ClassificationMethod, y=CER.means, color = YearIncluded) + 
  geom_point(aes(shape = YearIncluded), size = 2.5) +
  facet_wrap(~EmbeddingMethod, ncol = 4)+
  geom_hline(yintercept = 0.116, linetype = 'dashed', size =1)+
  xlab("Classification Method") +
  ylab("Sensitivity Rate")+
  theme_bw()+
  theme(legend.position = "bottom",axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

(ref:senspf-CEF) $C \times E \times F$, F-ratio = `r round(df.ano.sens.pf.multi$Frat[14],3)`. The effect of classification method, embedding method, and filtering threshold on the sensitivity of a pants-on-fire label. Each classification method is represented by a letter. T is for classification tree, and G is for ordinal regression. All others are based on the first letter of the method name. Only the means are plotted here. Violin plots are not used due to the number of levels of filtering threshold.

```{r senspf-CEF, echo=FALSE, message=FALSE,warning=FALSE,tidy=TRUE,fig.cap="(ref:senspf-CEF)", fig.height=7, fig.align='center', cache=TRUE}
CEF.sens.pf$ClassificationMethod <- gsub("OrdReg", "G", CEF.sens.pf$ClassificationMethod)
CEF.sens.pf$ClassificationMethod <- gsub("LDA", "L", CEF.sens.pf$ClassificationMethod)
CEF.sens.pf$ClassificationMethod <- gsub("QDA", "Q", CEF.sens.pf$ClassificationMethod)
CEF.sens.pf$ClassificationMethod <- gsub("MDA", "M", CEF.sens.pf$ClassificationMethod)
CEF.sens.pf$ClassificationMethod <- gsub("FDA", "F", CEF.sens.pf$ClassificationMethod)
CEF.sens.pf$ClassificationMethod <- gsub("Tree", "T", CEF.sens.pf$ClassificationMethod)
CEF.sens.pf$ClassificationMethod <- gsub("RF", "R", CEF.sens.pf$ClassificationMethod)
CEF.sens.pf$ClassificationMethod <- factor(CEF.sens.pf$ClassificationMethod, levels = c("L","Q","M","F","G","T","R"))

CEF.sens.pf %>% ggplot() + aes(x = EmbeddingMethod, y=CEF.means, color = ClassificationMethod) + 
  geom_text(aes(label = ClassificationMethod)) +
  facet_wrap(~FilterMinAppear_F, ncol = 2)+
  geom_hline(yintercept = 0.116, linetype = 'dashed', size =1)+
  scale_color_manual(values = colrs.class)+
  xlab("Embedding Method") +
  ylab("Sensitivity Rate")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")
```

(ref:EmbYearVi-senspf) $E \times R$,  F-ratio = `r round(df.ano.sens.pf.multi$Frat[12],3)`. The effect of including year as a predictor by embedding method on the sensitivity of a pants-on-fire label. The median is a black triangle, and the mean is a grey circle.

```{r EmbYearVi-senspf, echo = FALSE, tidy  = TRUE,warning=FALSE, fig.cap="(ref:EmbYearVi-senspf)", fig.height=7, fig.align='center', cache=TRUE}
data.multi.filter %>% 
   ggplot(aes(x = YearIncluded, y = Sensitivity_PantsFire, fill = YearIncluded)) +
   geom_violin(trim=TRUE, position = position_dodge(1))  +
   stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
   stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
   facet_wrap(~EmbeddingMethod, ncol=4)+
   geom_hline(yintercept = 0.116, linetype = 'dashed', size =1)+
   xlab("Include Year?") +
   ylab("Sensitivity Rate")+
   theme_bw()+
   theme(legend.position = "none")
```

(ref:ClassYearVi-senspf) $C \times R$,  F-ratio = `r round(df.ano.sens.pf.multi$Frat[12],3)`. The effect of including year as a predictor by classification method on the sensitivity of a pants-on-fire label. The median is a black triangle, and the mean is a grey circle.

```{r ClassYearVi-senspf, echo = FALSE, tidy  = TRUE,warning=FALSE, fig.cap="(ref:ClassYearVi-senspf)", fig.height=7, fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = YearIncluded, y = Sensitivity_PantsFire, fill = YearIncluded)) +
  geom_violin(trim=TRUE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~ClassificationMethod,ncol=2)+
  geom_hline(yintercept = 0.116, linetype = 'dashed', size =1)+
  xlab("Include Year?") +
  ylab("Sensitivity Rate")+
  theme_bw()+
  theme(legend.position = "none") 
```

(ref:ClassMinVi-senspf) $C \times F$,  F-ratio = `r round(df.ano.sens.pf.multi$Frat[9],3)`. The effect of filtering threshold by classification method on the sensitivity of a pants-on-fire label. The median is a black triangle, and the mean is a grey circle.

```{r ClassMinVi-senspf, echo = FALSE, tidy  = TRUE,warning=FALSE, fig.cap="(ref:ClassMinVi-senspf)", fig.height=7, fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = FilterMinAppear_F, y = Sensitivity_PantsFire, fill = FilterMinAppear_F)) +
  geom_violin(trim=TRUE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~ClassificationMethod,ncol=2)+
  geom_hline(yintercept = 0.116, linetype = 'dashed', size =1)+
  xlab("Minimum Number of Appearances") +
  ylab("Sensitivity Rate")+
  theme_bw()+
  theme(legend.position = "none") 
```

(ref:ClassStopVi-senspf) $C \times S$,  F-ratio = `r round(df.ano.sens.pf.multi$Frat[7],3)`. The effect of filtering stop words by classification method on the sensitivity of a pants-on-fire label. The median is a black triangle, and the mean is a grey circle.

```{r ClassStopVi-senspf, echo = FALSE, tidy  = TRUE,warning=FALSE, fig.cap="(ref:ClassStopVi-senspf)", fig.height=7, fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = FilterStopwords, y = Sensitivity_PantsFire, fill = FilterStopwords)) +
  geom_violin(trim=TRUE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~ClassificationMethod,ncol=2)+
  geom_hline(yintercept = 0.116, linetype = 'dashed', size =1)+
  xlab("Filter Stop Words?") +
  ylab("Sensitivity Rate")+
  theme_bw()+
  theme(legend.position = "none") 
```

(ref:ClassEmbVi-senspf) $C \times E$,  F-ratio = `r round(df.ano.sens.pf.multi$Frat[6],3)`. The effect of classification method by embedding method on the sensitivity of the pants-on-fire label. Discriminant analyses are in blue. Logistic regression is red, and tree-based methods are in green. The median is a black triangle, and the mean is a grey circle.

```{r ClassEmbVi-senspf, echo = FALSE, tidy  = TRUE, warning=FALSE, fig.cap="(ref:ClassEmbVi-senspf)", fig.height=7, fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = ClassificationMethod, y = Sensitivity_PantsFire, fill = ClassificationMethod)) +
  geom_violin(trim=TRUE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~EmbeddingMethod, ncol=4)+
  geom_hline(yintercept = 0.116, linetype = 'dashed', size =1)+
  scale_fill_manual(values = colrs.class) +
  xlab("Embedding Method") +
  ylab("Sensitivity Rate")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")
```

(ref:senspf-Year) $R$,  F-ratio = `r round(df.ano.sens.pf.multi$Frat[5],3)`. The effect of including year as a predictor on the sensitivity of the pants-on-fire label. The median is a black triangle, and the mean is a grey circle.

```{r senspf-Year, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE, fig.cap="(ref:senspf-Year)", fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = YearIncluded, y = Sensitivity_PantsFire, fill = YearIncluded)) +
  geom_violin(trim=TRUE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.116, linetype = 'dashed', size =1)+
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Include Year?") +
  ylab("Sensitivity Rate")
```

(ref:senspf-Min) $F$,  F-ratio = `r round(df.ano.sens.pf.multi$Frat[4],3)`. The effect of filtering threshold on the sensitivity of the pants-on-fire label. The median is a black triangle, and the mean is a grey circle.

```{r senspf-Min, echo=FALSE,warning=FALSE, message=FALSE, tidy=TRUE, fig.cap="(ref:senspf-Min)", fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = FilterMinAppear_F, y = Sensitivity_PantsFire, fill = FilterMinAppear_F)) +
  geom_violin(trim=TRUE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.116, linetype = 'dashed', size =1)+
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Minimum Number of Appearances") +
  ylab("Sensitivity Rate")
```

(ref:senspf-Stop) $S$,  F-ratio = `r round(df.ano.sens.pf.multi$Frat[3],3)`. The effect of filtering stop words on the sensitivity of the pants-on-fire label. The median is a black triangle, and the mean is a grey circle.

```{r senspf-Stop, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE, fig.cap="(ref:senspf-Stop)", fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = FilterStopwords, y = Sensitivity_PantsFire, fill = FilterStopwords)) +
  geom_violin(trim=TRUE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.116, linetype = 'dashed', size =1)+
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Filter Stop Words?") +
  ylab("Sensitivity Rate")
```

(ref:senspf-Emb) $E$, F-ratio = `r round(df.ano.sens.pf.multi$Frat[2],3)`. The effect of embedding method on the sensitivity of a pants-on-fire label. Word2Vec Continuous Bag of Words are in the blue-green shades, and Word2Vec Skip-Gram are in the blue-purple shades. GloVe is in the brown-orange shades. BERT is in pink, and PCA is in green. The median is a black triangle, and the mean is a grey circle.

```{r senspf-Emb, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE, fig.cap="(ref:senspf-Emb)", fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = EmbeddingMethod, y = Sensitivity_PantsFire, fill = EmbeddingMethod)) +
  geom_violin(trim=TRUE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.116, linetype = 'dashed', size =1)+
  scale_fill_manual(values = colrs.emb)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")+
  xlab("Embedding Method") +
  ylab("Sensitivity Rate")
```

(ref:senspf-Class) $C$, F-ratio = `r round(df.ano.sens.pf.multi$Frat[1],3)`. The effect of classification method on the sensitivity of a pants-on-fire label. Discriminant analyses are in blue. Logistic regression is red, and tree-based methods are in green. The median is a black triangle, and the mean is a grey circle.

```{r senspf-Class, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE, fig.cap="(ref:senspf-Class)", fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = ClassificationMethod, y = Sensitivity_PantsFire, fill = ClassificationMethod)) +
  geom_violin(trim=TRUE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  geom_hline(yintercept = 0.116, linetype = 'dashed', size =1)+
  scale_fill_manual(values = colrs.class)+
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Classification Method") +
  ylab("Sensitivity Rate")
```

(ref:specpf-CER) $C \times E \times R$, F-ratio = `r round(df.ano.spec.pf.multi$Frat[15],3)`. The effect of classification method, embedding method, and inclusion of year as a predictor on the specificity of a pants-on-fire label. Only the means are plotted here. Violin plots are not used due to the unbalanced number of combinations between the levels since there were computational issues. There are fewer combinations observed when year is included as a predictor.

```{r specpf-CER, echo=FALSE, message=FALSE,warning=FALSE,tidy=TRUE,fig.cap="(ref:specpf-CER)", fig.height=7, fig.align='center', cache=TRUE}
CER.spec.pf %>% 
  ggplot() + aes(x = ClassificationMethod, y=CER.means, color = YearIncluded) + 
  geom_point(aes(shape = YearIncluded), size = 2.5) +
  facet_wrap(~EmbeddingMethod, ncol = 4)+
  xlab("Classification Method") +
  ylab("Specificity Rate")+
  theme_bw()+
  theme(legend.position = "bottom",axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

(ref:specpf-CEF) $C \times E \times F$, F-ratio = `r round(df.ano.spec.pf.multi$Frat[14],3)`. The effect of classification method, embedding method, and filtering threshold on the specificity of a pants-on-fire label. Each classification method is represented by a letter. T is for classification tree, and G is for ordinal regression. All others are based on the first letter of the method name. Only the means are plotted here. Violin plots are not used due to the number of levels of filtering threshold.

```{r specpf-CEF, echo=FALSE, message=FALSE,warning=FALSE,tidy=TRUE,fig.cap="(ref:specpf-CEF)", fig.height=7, fig.align='center', cache=TRUE}
CEF.spec.pf$ClassificationMethod <- gsub("OrdReg", "G", CEF.spec.pf$ClassificationMethod)
CEF.spec.pf$ClassificationMethod <- gsub("LDA", "L", CEF.spec.pf$ClassificationMethod)
CEF.spec.pf$ClassificationMethod <- gsub("QDA", "Q", CEF.spec.pf$ClassificationMethod)
CEF.spec.pf$ClassificationMethod <- gsub("MDA", "M", CEF.spec.pf$ClassificationMethod)
CEF.spec.pf$ClassificationMethod <- gsub("FDA", "F", CEF.spec.pf$ClassificationMethod)
CEF.spec.pf$ClassificationMethod <- gsub("Tree", "T", CEF.spec.pf$ClassificationMethod)
CEF.spec.pf$ClassificationMethod <- gsub("RF", "R", CEF.spec.pf$ClassificationMethod)
CEF.spec.pf$ClassificationMethod <- factor(CEF.spec.pf$ClassificationMethod, levels = c("L","Q","M","F","G","T","R"))

CEF.spec.pf %>% ggplot() + aes(x = EmbeddingMethod, y=CEF.means, color = ClassificationMethod) + 
  geom_text(aes(label = ClassificationMethod)) +
  facet_wrap(~FilterMinAppear_F, ncol = 2)+
  scale_color_manual(values = colrs.class)+
  xlab("Embedding Method") +
  ylab("Specificity Rate")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")
```

(ref:EmbYearVi-specpf) $E \times R$,  F-ratio = `r round(df.ano.spec.pf.multi$Frat[12],3)`. The effect of including year as a predictor by embedding method on the specificity of a pants-on-fire label. The median is a black triangle, and the mean is a grey circle.

```{r EmbYearVi-specpf, echo = FALSE, tidy  = TRUE,warning=FALSE, fig.cap="(ref:EmbYearVi-specpf)", fig.height=7, fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = YearIncluded, y = Specificity_PantsFire, fill = YearIncluded)) +
  geom_violin(trim=TRUE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~EmbeddingMethod, ncol=4)+
  xlab("Include Year?") +
  ylab("Specificity Rate")+
  theme_bw()+
  theme(legend.position = "none")
```

(ref:ClassYearVi-specpf) $C \times R$,  F-ratio = `r round(df.ano.spec.pf.multi$Frat[11],3)`. The effect of including year as a predictor by classification method on the specificity of a pants-on-fire label. The median is a black triangle, and the mean is a grey circle.

```{r ClassYearVi-specpf, echo = FALSE, tidy  = TRUE,warning=FALSE, fig.cap="(ref:ClassYearVi-specpf)", fig.height=7, fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = YearIncluded, y = Specificity_PantsFire, fill = YearIncluded)) +
  geom_violin(trim=TRUE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~ClassificationMethod,ncol=2)+
  xlab("Include Year?") +
  ylab("Specificity Rate")+
  theme_bw()+
  theme(legend.position = "none") 
```

(ref:EmbMinVi-specpf) $E \times F$,  F-ratio = `r round(df.ano.spec.pf.multi$Frat[10],3)`. The effect of filtering threshold by embedding method on the specificity of a pants-on-fire label. The median is a black triangle, and the mean is a grey circle.

```{r EmbMinVi-specpf, echo = FALSE, tidy  = TRUE,warning=FALSE, fig.cap="(ref:EmbMinVi-specpf)", fig.height=7, fig.align='center', cache=TRUE}
data.multi.filter %>%
  ggplot(aes(x = FilterMinAppear_F, y = Specificity_PantsFire, fill = FilterMinAppear_F)) +
  geom_violin(trim=TRUE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~EmbeddingMethod, ncol=4)+
  xlab("Minimum Number of Appearances") +
  ylab("Specificity Rate")+
  theme_bw()+
  theme(legend.position = "none")
```

(ref:ClassMinVi-specpf) $C \times F$,  F-ratio = `r round(df.ano.spec.pf.multi$Frat[9],3)`. The effect of filtering threshold by classification method on the specificity of a pants-on-fire label. The median is a black triangle, and the mean is a grey circle.

```{r ClassMinVi-specpf, echo = FALSE, tidy  = TRUE,warning=FALSE, fig.cap="(ref:ClassMinVi-specpf)", fig.height=7, fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = FilterMinAppear_F, y = Specificity_PantsFire, fill = FilterMinAppear_F)) +
  geom_violin(trim=TRUE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~ClassificationMethod,ncol=2)+
  xlab("Minimum Number of Appearances") +
  ylab("Specificity Rate")+
  theme_bw()+
  theme(legend.position = "none") 
```

(ref:ClassStopVi-specpf) $C \times S$,  F-ratio = `r round(df.ano.spec.pf.multi$Frat[7],3)`. The effect of filtering stop words by classification method on the specificity of a pants-on-fire label. The median is a black triangle, and the mean is a grey circle.

```{r ClassStopVi-specpf, echo = FALSE, tidy  = TRUE,warning=FALSE, fig.cap="(ref:ClassStopVi-specpf)", fig.height=7, fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = FilterStopwords, y = Specificity_PantsFire, fill = FilterStopwords)) +
  geom_violin(trim=TRUE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~ClassificationMethod,ncol=2)+
  xlab("Filter Stop Words?") +
  ylab("Specificity Rate")+
  theme_bw()+
  theme(legend.position = "none") 
```

(ref:ClassEmbVi-specpf) $C \times E$,  F-ratio = `r round(df.ano.spec.pf.multi$Frat[6],3)`. The effect of classification method by embedding method on the specificity of the pants-on-fire label. Discriminant analyses are in blue. Logistic regression is red, and tree-based methods are in green. The median is a black triangle, and the mean is a grey circle.

```{r ClassEmbVi-specpf, echo = FALSE, tidy  = TRUE, warning=FALSE, fig.cap="(ref:ClassEmbVi-specpf)", fig.height=7, fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = ClassificationMethod, y = Specificity_PantsFire, fill = ClassificationMethod)) +
  geom_violin(trim=TRUE, position = position_dodge(1))  +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  facet_wrap(~EmbeddingMethod, ncol=4)+
  scale_fill_manual(values = colrs.class) +
  xlab("Embedding Method") +
  ylab("Specificity Rate")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")
```

(ref:specpf-Year) $R$,  F-ratio = `r round(df.ano.spec.pf.multi$Frat[5],3)`. The effect of including year as a predictor on the specificity of the pants-on-fire label. The median is a black triangle, and the mean is a grey circle.

```{r specpf-Year, echo=FALSE,warning=FALSE, message=FALSE, tidy=TRUE, fig.cap="(ref:specpf-Year)", fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = YearIncluded, y = Specificity_PantsFire, fill = YearIncluded)) +
  geom_violin(trim=TRUE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Include Year?") +
  ylab("Specificity Rate")
```

(ref:specpf-Stop) $S$,  F-ratio = `r round(df.ano.spec.pf.multi$Frat[3],3)`. The effect of filtering stop words on the specificity of the pants-on-fire label. The median is a black triangle, and the mean is a grey circle.

```{r specpf-Stop, echo=FALSE,warning=FALSE, message=FALSE, tidy=TRUE, fig.cap="(ref:specpf-Stop)", fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = FilterStopwords, y = Specificity_PantsFire, fill = FilterStopwords)) +
  geom_violin(trim=TRUE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Filter Stop Words?") +
  ylab("Specificity Rate")
```

(ref:specpf-Emb) $E$, F-ratio = `r round(df.ano.spec.pf.multi$Frat[2],3)`. The effect of embedding method on the specificity of a pants-on-fire label. Word2Vec Continuous Bag of Words are in the blue-green shades, and Word2Vec Skip-Gram are in the blue-purple shades. GloVe is in the brown-orange shades. BERT is in pink, and PCA is in green. The median is a black triangle, and the mean is a grey circle.

```{r specpf-Emb, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE, fig.cap="(ref:specpf-Emb)", fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = EmbeddingMethod, y = Specificity_PantsFire, fill = EmbeddingMethod)) +
  geom_violin(trim=TRUE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  scale_fill_manual(values = colrs.emb)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")+
  xlab("Embedding Method") +
  ylab("Specificity Rate")
```

(ref:specpf-Class) $C$, F-ratio = `r round(df.ano.sens.pf.multi$Frat[1],3)`. The effect of classification method on the specificity of a pants-on-fire label. Discriminant analyses are in blue. Logistic regression is red, and tree-based methods are in green. The median is a black triangle, and the mean is a grey circle.

```{r specpf-Class, echo=FALSE,warning=FALSE, message=FALSE,tidy=TRUE, fig.cap="(ref:specpf-Class)", fig.align='center', cache=TRUE}
data.multi.filter %>% 
  ggplot(aes(x = ClassificationMethod, y = Specificity_PantsFire, fill = ClassificationMethod)) +
  geom_violin(trim=TRUE) +
  stat_summary(fun = mean, geom = "point", shape = 16, size = 2, color = '#E2DFDF') +
  stat_summary(fun = median, geom = "point", shape = 17, size = 2) +
  scale_fill_manual(values = colrs.class)+
  theme_bw()+
  theme(legend.position = "none") +
  xlab("Classification Method") +
  ylab("Specificity Rate")
```

# Code

The following code was ran using the Crane server at the Holland Computing Center, located at the University of Nebraska-Lincoln.

**Binary Classification**

*Bag of Words*

```
library(tidyverse)
library(tidytext)
library(textdata)
library(text2vec)
library(keras)
library(uwot)
library(tensorflow)
library(nomclust)
library(ggplot2)
library(caret)
library(doParallel)

set.seed(121565)

############## COMBINING DATA SETS ############################

rawdata_train <- read.csv(file = "/work/wtp/jhaus4/fnn_train.csv", 
                          header = T,
                          stringsAsFactors = F)
rawdata_test <- read.csv(file = "/work/wtp/jhaus4/fnn_test.csv", 
                         header = T,
                         stringsAsFactors = F)
rawdata_valid <- read.csv(file = "/work/wtp/jhaus4/fnn_dev.csv", 
                         header = T,
                         stringsAsFactors = F)
rawdata <- rbind(rawdata_train, rawdata_valid, rawdata_test)

data <- rawdata %>%
  mutate(newsTextClean=gsub('[[:punct:]]+', '',
                       gsub('\\\\n|\\.|\\,|\\;',' ',
                       gsub("[^[:alnum:]]", " ",
                       (substr(statement,1,nchar(statement)-1))))))
#For all lowercase
#tolower(substr(statement,1,nchar(statement)-1))

news_tokens <- data %>% select(id, label_fnn, newsTextClean) %>%
  unnest_tokens(word, newsTextClean, to_lower = FALSE) %>%
  #Use just "[a-z']+" for lower case letters
  #Change to "[[:alnum:]]+" for numbers to be included
  #Change to "[A-z']+" for all cases
  mutate(word = str_extract(word, "[[:alnum:]]+"))
news_tokens <- news_tokens %>% drop_na(word)
#news_tokens <- news_tokens %>% anti_join(stop_words)

news_new <- news_tokens %>% group_by(word) %>%
  mutate(token_freq = n()) %>%
  filter(token_freq >=60) %>%
  group_by(id, label_fnn) %>%
  summarise(newsTextClean = str_c(word, collapse = " "))

#Getting the labels
y <- news_new %>% select(label_fnn) %>% pull() %>% as.array()
y <- as.factor(y)
levels(y)
y <- ifelse(y == "fake", 0, 1)

it <- itoken(news_new$newsTextClean,
                  tokenizer = word_tokenizer,
                  ids = news_new$id,
                  progressbar = T, tolower = FALSE)
vocab <- create_vocabulary(it)
vocab <- prune_vocabulary(vocab)
vectorizer <- vocab_vectorizer(vocab)
news_new <- news_new %>% select(newsTextClean) %>% pull()

#Vectorize tokens - token receiving a unique integer
tokenizer <- text_tokenizer(lower = FALSE) %>% 
              fit_text_tokenizer(news_new)

#put integers in a sequence
sequences<- texts_to_sequences(tokenizer, news_new)

##########################Document-term matrix all########################
un.words <- length(tokenizer$word_index)
docs <- length(sequences)
dtm <- matrix(0, nrow = docs, ncol = un.words)
for (i in 1:docs){
  word.vec <- sequences[[i]]
  c <- length(sequences[[i]])
  a <- 0
  for (j in 1:c){
    a <- a + 1
    b <- word.vec[a]
    dtm[i,b] <- dtm[i,b] + 1
  }
}

dtm_y <- cbind(dtm, y)
dtm_y <- as.data.frame(dtm_y)

words <- unlist(tokenizer$index_word, use.names = TRUE)
words <- c(words, "PolitiFactRating")

colnames(dtm_y) <- words



trainIndex <- createDataPartition(dtm_y$PolitiFactRating, 
                                  p = .8, list = F, times = 1)

dtm_train_y <- dtm_y[trainIndex,]
dtm_test_y <- dtm_y[-trainIndex,]

mean(dtm_train_y$PolitiFactRating)
mean(dtm_test_y$PolitiFactRating)

dtm_train_y$PolitiFactRating <- as.factor(dtm_train_y$PolitiFactRating)
dtm_test_y$PolitiFactRating <- as.factor(dtm_test_y$PolitiFactRating)

###################### BoW CV ################

train.control <- trainControl(method = "cv", number = 10)
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

#Logistic regression directly on DTM
start_time <- Sys.time()
model <- train(PolitiFactRating ~ ., data = dtm_train_y,
               trControl = train.control, method = "glm",
                family="binomial", control = list(maxit = 50))
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions, dtm_test_y$PolitiFactRating) 

#Linear Discriminant Analysis directly on DTM
start_time <- Sys.time()
model <- train(PolitiFactRating ~ ., data = dtm_train_y,
               trControl = train.control, method = "lda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions, dtm_test_y$PolitiFactRating)

#Quadratic Discriminant Analysis directly on DTM
#start_time <- Sys.time()
#model <- train(PolitiFactRating ~ ., data = dtm_train_y, 
#               trControl = train.control, method = "qda")
#end_time <- Sys.time()
#glm.time <- end_time - start_time
#glm.time
#model
#predictions <- model %>% predict(dtm_test_y)
#confusionMatrix(predictions, dtm_test_y$PolitiFactRating)

#Mixture Discriminant Analysis directly on DTM
library(mda)
#start_time <- Sys.time()
#model <- train(PolitiFactRating ~ ., data = dtm_train_y, 
#               trControl = train.control, method = "mda")
#end_time <- Sys.time()
#glm.time <- end_time - start_time
#glm.time
#model
#predictions <- model %>% predict(dtm_test_y)
#confusionMatrix(predictions, dtm_test_y$PolitiFactRating)

#Flexible Discriminant Analysis directly on DTM
#library(earth)
#start_time <- Sys.time()
#model <- train(PolitiFactRating ~ ., data = dtm_train_y, 
#               trControl = train.control, method = "fda")
#end_time <- Sys.time()
#glm.time <- end_time - start_time
#glm.time
#model
#predictions <- model %>% predict(dtm_test_y)
#confusionMatrix(predictions, dtm_test_y$PolitiFactRating)

#Classification trees directly on DTM
library(rpart)
start_time <- Sys.time()
cpGrid <- expand.grid(.cp=seq(0.01, 0.5,0.01))
model <- train(PolitiFactRating ~ ., data = dtm_train_y, 
               trControl = train.control, method = "rpart",
               tuneGrid = cpGrid)
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions, dtm_test_y$PolitiFactRating)


### Random Forest
library(randomForest)
start_time <- Sys.time()
mtry <- floor(sqrt(ncol(dtm_train_y)-1))
if (mtry > 10){
  a <- mtry - 10
} else {a <- mtry}
b <- mtry + 10
mtryGrid <- expand.grid(.mtry=seq(a, b, 1))
model <- train(PolitiFactRating ~ ., data = dtm_train_y, 
               trControl = train.control, method = "rf",
               tuneGrid = mtryGrid)
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions, dtm_test_y$PolitiFactRating)
```

*BERT*

```
library(tidyverse)
library(tidytext)
library(textdata)
library(text2vec)
library(keras)
library(uwot)
library(tensorflow)
library(nomclust)
library(ggplot2)
library(word2vec)
library(caret)
library(doParallel)

set.seed(121565)

rawdata_train <- read.csv(file = "/work/wtp/jhaus4/fnn_train.csv", 
                          header = T,
                          stringsAsFactors = F)
rawdata_test <- read.csv(file = "/work/wtp/jhaus4/fnn_test.csv", 
                         header = T,
                         stringsAsFactors = F)
rawdata_valid <- read.csv(file = "/work/wtp/jhaus4/fnn_dev.csv", 
                          header = T,
                          stringsAsFactors = F)
rawdata <- rbind(rawdata_train, rawdata_valid, rawdata_test)

data <- rawdata %>%
  mutate(newsTextClean=gsub('[[:punct:]]+', '',
                       gsub('\\\\n|\\.|\\,|\\;',' ',
                       gsub("[^[:alnum:]]", " ",
                       (substr(statement,1,nchar(statement)-1))))))
#For all lowercase
#tolower(substr(statement,1,nchar(statement)-1))

news_tokens <- data %>% select(id, label_fnn, newsTextClean) %>%
  unnest_tokens(word, newsTextClean, to_lower = FALSE) %>%
  #Use just "[a-z']+" for lower case letters
  #Change to "[[:alnum:]]+" for numbers and cases to be included
  #Change to "[A-z']+" for all cases
  mutate(word = str_extract(word, "[[:alnum:]]+"))
news_tokens <- news_tokens %>% drop_na(word)
#news_tokens <- news_tokens %>% anti_join(stop_words)

news_new <- news_tokens %>% group_by(word) %>%
  mutate(token_freq = n()) %>%
  filter(token_freq >=60) %>%
  group_by(id, label_fnn) %>%
  summarise(newsTextClean = str_c(word, collapse = " "))

trainIndex <- createDataPartition(news_new$label_fnn, 
                                  p = .8, list = F, times = 1)
train.control <- trainControl(method = "cv", number = 10)
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

news_new_train <- news_new[trainIndex,]
news_new_test <- news_new[-trainIndex,]

#write.csv(news_new_train, 
          "fnntrain60NumbersUpperStopwords.csv", 
          row.names = FALSE)
#write.csv(news_new_test, 
          "fnntest60NumbersUpperStopwords.csv", 
          row.names = FALSE)

bert_train <- read.csv(file = 
                      "BERT_Train_60_Numbers_Upper_Stopwords.csv", 
                      header = F)
dim(bert_train)
bert_train <- bert_train[-1,]
dim(bert_train)

bert_test <- read.csv(file =  
            "BERT_Test_60_Numbers_Upper_Stopwords.csv", 
            header = F)
dim(bert_test)
bert_test <- bert_test[-1,]
dim(bert_test)

#Getting the labels
y_train <- news_new_train %>% select(label_fnn) %>% pull() %>% as.array()
y_test <- news_new_test %>% select(label_fnn) %>% pull() %>% as.array()
y_train <- as.factor(y_train)
y_test <- as.factor(y_test)
levels(y_train)
levels(y_test)
y_train <- ifelse(y_train == "fake", 0, 1)
y_test <- ifelse(y_test == "fake", 0, 1)

dtm_train_y <- cbind(bert_train, y_train)
dtm_train_y <- as.data.frame(dtm_train_y)
dtm_test_y <- cbind(bert_test, y_test)
dtm_test_y <- as.data.frame(dtm_test_y)

dtm_train_y$y_train <- as.factor(dtm_train_y$y_train)
dtm_test_y$y_test <- as.factor(dtm_test_y$y_test)

##### CV DIM#####


#Logistic regression directly on DTM
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "glm",
               family="binomial", control = list(maxit = 50))
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)


#Linear Discriminant Analysis directly on DTM
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "lda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)


#Quadratic Discriminant Analysis directly on DTM
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "qda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)


#Mixture Discriminant Analysis directly on DTM
library(mda)
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "mda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)


#Flexible Discriminant Analysis directly on DTM
library(earth)
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "fda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)


#Classification trees directly on DTM
library(rpart)
start_time <- Sys.time()
cpGrid <- expand.grid(.cp=seq(0.01, 0.5,0.01))
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "rpart",
               tuneGrid = cpGrid)
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

### Random Forest
library(randomForest)
start_time <- Sys.time()
mtry <- floor(sqrt(ncol(dtm_train_y)-1))
if (mtry > 10){
  a <- mtry - 10
} else {a <- mtry}
b <- mtry + 10
mtryGrid <- expand.grid(.mtry=seq(a, b, 1))
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "rf",
               tuneGrid = mtryGrid)
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)
```

*BERT, Python portion* [@reimer_2022]

```
import tensorflow as tf
import torch
import pandas as pd

df_train = pd.read_csv("fnntrain60NumbersUpperStopwords.csv")
df_test = pd.read_csv("fnntest60NumbersUpperStopwords.csv")

#Get the lists of sentences and their labels.
sentences_train = df_train.newsTextClean.values
sentences_test = df_test.newsTextClean.values

from sentence_transformers import SentenceTransformer, models

#change to 'bert-base-cased' to tell difference between 
#upper and lower case
word_embedding_model = models.Transformer('bert-base-uncased',
max_seq_length=120)
pooling_model = models.Pooling(word_embedding_model.
get_word_embedding_dimension())

sbert_model = SentenceTransformer(modules=[word_embedding_model, 
pooling_model])

document_train = sbert_model.encode(sentences_train)
document_test = sbert_mode.encode(sentences_test)

df_train.to_csv("BERT_Train_60_Numbers_Upper_Stopwords.csv")
df_test.to_csv("BERT_Test_60_Numbers_Upper_Stopwords.csv")
```

*GloVe*

```
library(tidyverse)
library(tidytext)
library(textdata)
library(text2vec)
library(keras)
library(uwot)
library(tensorflow)
library(nomclust)
library(ggplot2)
library(word2vec)
library(caret)
library(doParallel)
library(pROC)

set.seed(121565)

############## COMBINING DATA SETS ############################

rawdata_train <- read.csv(file = "DataFakeNewsNets/fnn_train.csv", 
                          header = T,
                          stringsAsFactors = F)
rawdata_test <- read.csv(file = "DataFakeNewsNets/fnn_test.csv", 
                         header = T,
                         stringsAsFactors = F)
rawdata_valid <- read.csv(file = "DataFakeNewsNets/fnn_dev.csv", 
                          header = T,
                          stringsAsFactors = F)
rawdata <- rbind(rawdata_train, rawdata_valid, rawdata_test)

data <- rawdata %>%
  mutate(newsTextClean=gsub('[[:punct:]]+', '',
                       gsub('\\\\n|\\.|\\,|\\;',' ',
                       gsub("[^[:alnum:]]", " ",
                       tolower(substr(statement,1,nchar(statement)-1))))))
data <- data %>% separate(date, c("Year", "Month", "Day","Junk"), sep = "-")
#For all lowercase
#tolower(substr(statement,1,nchar(statement)-1))

news_tokens <- data %>% select(id, label_fnn, Year, newsTextClean) %>%
  unnest_tokens(word, newsTextClean, to_lower = FALSE) %>%
  #Use just "[a-z']+" for lower case letters
  #Change to "[[:alnum:]]+" for numbers and cases to be included
  #Change to "[A-z']+" for all cases
  mutate(word = str_extract(word, "[a-z']+"))
news_tokens <- news_tokens %>% drop_na(word)
news_tokens <- news_tokens %>% anti_join(stop_words)

news_new <- news_tokens %>% group_by(word) %>%
  mutate(token_freq = n()) %>%
  filter(token_freq >= 5) %>%
  group_by(id, label_fnn, Year) %>%
  summarise(newsTextClean = str_c(word, collapse = " "))

max.length <- max(str_count(news_new$newsTextClean, "[[:alnum:]]+"))

trainIndex <- createDataPartition(news_new$label_fnn, 
                                  p = .8, list = F, times = 1)
train.control <- trainControl(method = "cv", number = 10)

news_new_train <- news_new[trainIndex,]
news_new_test <- news_new[-trainIndex,]


#Getting the labels
y_train <- news_new_train %>% select(label_fnn) %>% pull() %>% as.array()
y_test <- news_new_test %>% select(label_fnn) %>% pull() %>% as.array()
y_train <- as.factor(y_train)
y_test <- as.factor(y_test)
levels(y_train)
levels(y_test)
y_train <- ifelse(y_train == "fake", 0, 1)
y_test <- ifelse(y_test == "fake", 0, 1)

year_train <- news_new_train %>% select(Year) %>% pull() %>% as.array()
year_test <- news_new_test %>% select(Year) %>% pull() %>% as.array()
year_train <- as.factor(year_train)
year_test <- as.factor(year_test)
levels(year_train)
levels(year_test)

it_train <- itoken(news_new_train$newsTextClean,
                   tokenizer = word_tokenizer,
                   ids = news_new$id,
                   progressbar = T, tolower = FALSE)
it_test <- itoken(news_new_test$newsTextClean,
                  tokenizer = word_tokenizer,
                  ids = news_new$id,
                  progressbar = T, tolower = FALSE)
vocab_train <- create_vocabulary(it_train)
vocab_test <- create_vocabulary(it_test)
vocab_train <- prune_vocabulary(vocab_train)
vocab_test <- prune_vocabulary(vocab_test)
vectorizer_train <- vocab_vectorizer(vocab_train)
vectorizer_test <- vocab_vectorizer(vocab_test)
news_new_train <- news_new_train %>% select(newsTextClean) %>% pull()
news_new_test <- news_new_test %>% select(newsTextClean) %>% pull()

#Vectorize tokens - token receiving a unique integer
tokenizer_train <- text_tokenizer(lower = FALSE) %>% 
                    fit_text_tokenizer(news_new_train)
tokenizer_test <- text_tokenizer(lower = FALSE) %>% 
                    fit_text_tokenizer(news_new_test)

#put integers in a sequence
sequences_train <- texts_to_sequences(tokenizer_train, news_new_train)
sequences_test <- texts_to_sequences(tokenizer_test, news_new_test)

dtm_train <- create_dtm(it_train, vectorizer_train)
dtm_train <- as.matrix(dtm_train)
dtm_test <- create_dtm(it_test, vectorizer_test)
dtm_test <- as.matrix(dtm_test)
tcm_train <- create_tcm(it_train, vectorizer_train,
                        skip_grams_window_context = c("symmetric"))
xmax <- max(tcm_train)

######################## GloVe Embedding Dim 300 ###############
glove_train <- GlobalVectors$new(rank = 300, x_max = xmax)
# This gets the embeddings for target words.
wv_tar_train <- glove_train$fit_transform(tcm_train, n_iter = 100)
dim(wv_tar_train)
# This gets the embedding for the context words.
wv_con_train <- glove_train$components
dim(wv_con_train)

word_vect_train <- wv_tar_train + t(wv_con_train)
dim(word_vect_train)
word_vect_train <- as.matrix(word_vect_train)

### Getting embeddings per document
intersection <- colnames(dtm_train) %in% rownames(word_vect_train)
dtm_train <- dtm_train[,intersection]
words <- colnames(dtm_train)
dtm_emb_train <- matrix(0, nrow = nrow(dtm_train), 
                  ncol = ncol(word_vect_train))
for (i in 1:nrow(dtm_train)){
  for (j in 1:ncol(dtm_train)){
    if (dtm_train[i,j] != 0){
      dtm_emb_train[i,] <- dtm_emb_train[i,] + dtm_train[i,j] * 
      word_vect_train[which(rownames(word_vect_train) == words[j]),]
    }
  }
}

int_test <- colnames(dtm_test) %in% rownames(word_vect_train)
dtm_test <- dtm_test[,int_test]
words_test <- colnames(dtm_test)
dtm_emb_test <- matrix(0, nrow = nrow(dtm_test), 
                  ncol = ncol(word_vect_train))
for (i in 1:nrow(dtm_test)){
  for (j in 1:ncol(dtm_test)){
    if (dtm_test[i,j] != 0){
      dtm_emb_test[i,] <- dtm_emb_test[i,] + dtm_test[i,j] * 
      word_vect_train[which(rownames(word_vect_train) == words_test[j]),]
    }
  }
}

dtm_train_y <- cbind(dtm_emb_train, y_train)
dtm_train_y <- as.data.frame(dtm_train_y)
dtm_test_y <- cbind(dtm_emb_test, y_test)
dtm_test_y <- as.data.frame(dtm_test_y)

dtm_train_y$y_train <- as.factor(dtm_train_y$y_train)
dtm_test_y$y_test <- as.factor(dtm_test_y$y_test)

train.control <- trainControl(method = "cv", number = 10)
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

##### CV 300 DIM#####

#Logistic regression directly on DTM
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "glm",
               family="binomial", control = list(maxit = 50))
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Linear Discriminant Analysis directly on DTM
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "lda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Quadratic Discriminant Analysis directly on DTM
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "qda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Mixture Discriminant Analysis directly on DTM
library(mda)
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "mda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Flexible Discriminant Analysis directly on DTM
library(earth)
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "fda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Classification trees directly on DTM
library(rpart)
start_time <- Sys.time()
cpGrid <- expand.grid(.cp=seq(0.01, 0.5,0.01))
model <- train(y_train ~ ., data = dtm_train_y,
               trControl = train.control, method = "rpart",
               tuneGrid = cpGrid)
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

### Random Forest
library(randomForest)
start_time <- Sys.time()
mtry <- floor(sqrt(ncol(dtm_train_y)-1))
if (mtry > 10){
  a <- mtry - 10
} else {a <- mtry}
b <- mtry + 10
mtryGrid <- expand.grid(.mtry=seq(a, b, 1))
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "rf",
               tuneGrid = mtryGrid)
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)
```

*PCA*

```
library(tidyverse)
library(tidytext)
library(textdata)
library(text2vec)
library(keras)
library(uwot)
library(tensorflow)
library(nomclust)
library(ggplot2)
library(caret)
library(doParallel)

set.seed(121565)

rawdata_train <- read.csv(file = "/work/wtp/jhaus4/fnn_train.csv", 
                          header = T,
                          stringsAsFactors = F)
rawdata_test <- read.csv(file = "/work/wtp/jhaus4/fnn_test.csv", 
                         header = T,
                         stringsAsFactors = F)
rawdata_valid <- read.csv(file = "/work/wtp/jhaus4/fnn_dev.csv", 
                          header = T,
                          stringsAsFactors = F)
rawdata <- rbind(rawdata_train, rawdata_valid, rawdata_test)

data <- rawdata %>%
  mutate(newsTextClean=gsub('[[:punct:]]+', '',
                       gsub('\\\\n|\\.|\\,|\\;',' ',
                       gsub("[^[:alnum:]]", " ",
                       (substr(statement,1,nchar(statement)-1))))))
#For all lowercase
#tolower(substr(statement,1,nchar(statement)-1))

news_tokens <- data %>% select(id, label_fnn, newsTextClean) %>%
  unnest_tokens(word, newsTextClean, to_lower = F) %>%
  #Use just "[a-z']+" for lower case letters
  #Change to "[[:alnum:]]+" for numbers and cases to be included
  #Change to "[A-z']+" for all cases
  mutate(word = str_extract(word, "[[:alnum:]]+"))
news_tokens <- news_tokens %>% drop_na(word)
#news_tokens <- news_tokens %>% anti_join(stop_words)

news_new <- news_tokens %>% group_by(word) %>%
  mutate(token_freq = n()) %>%
  filter(token_freq >= 60) %>%
  group_by(id, label_fnn) %>%
  summarise(newsTextClean = str_c(word, collapse = " "))

#Getting the labels
y <- news_new %>% select(label_fnn) %>% pull() %>% as.array()
y <- as.factor(y)
levels(y)
y <- ifelse(y == "fake", 0, 1)

it <- itoken(news_new$newsTextClean,
             tokenizer = word_tokenizer,
             ids = news_new$id,
             progressbar = T, tolower = F)
vocab <- create_vocabulary(it)
vocab <- prune_vocabulary(vocab)
vectorizer <- vocab_vectorizer(vocab)
news_new <- news_new %>% select(newsTextClean) %>% pull()

#Vectorize tokens - token receiving a unique integer
tokenizer <- text_tokenizer(lower = F) %>% fit_text_tokenizer(news_new)

#put integers in a sequence
sequences<- texts_to_sequences(tokenizer, news_new)

library(MASS)

#Document-term matrix all
un.words <- length(tokenizer$word_index)
docs <- length(sequences)
dtm <- matrix(0, nrow = docs, ncol = un.words)
for (i in 1:docs){
  word.vec <- sequences[[i]]
  c <- length(sequences[[i]])
  a <- 0
  for (j in 1:c){
    a <- a + 1
    b <- word.vec[a]
    dtm[i,b] <- dtm[i,b] + 1
  }
}

dtm_y <- cbind(y, dtm)
dtm_y <- as.data.frame(dtm_y)

words <- unlist(tokenizer$index_word, use.names = TRUE)
words <- c("PolitiFactRating", words)

colnames(dtm_y) <- words

trainIndex <- createDataPartition(dtm_y$PolitiFactRating, 
              p = .8, list = F, times = 1)

dtm_train_y <- dtm_y[trainIndex,]
dtm_test_y <- dtm_y[-trainIndex,]

mean(dtm_train_y$PolitiFactRating)
mean(dtm_test_y$PolitiFactRating)

dtm_train_y$PolitiFactRating <- as.factor(dtm_train_y$PolitiFactRating)
dtm_test_y$PolitiFactRating <- as.factor(dtm_test_y$PolitiFactRating)

dtm_train <- dtm_train_y[,-1]
pca_train <- prcomp(dtm_train, center = T)
pct_train <- (pca_train$sdev^2/sum(pca_train$sdev^2))*100
sum(pct_train[1:400])
embeds <- pca_train$rotation[,1:400]
pc_train <- as.matrix(dtm_train) %*% as.matrix(embeds)

pc_train_y <- cbind(dtm_train_y[,1],pc_train)
pc_train_y <- as.data.frame(pc_train_y)

pc_train_y$V1 <- ifelse(pc_train_y$V1 == 1, 0, 1)
pc_train_y$V1 <- as.factor(pc_train_y$V1)

pc_test <- as.matrix(dtm_test_y[,-1]) %*% as.matrix(embeds)

pc_test_y <- cbind( dtm_test_y[,1], pc_test)
pc_test_y <- as.data.frame(pc_test_y)

pc_test_y$V1 <- ifelse(pc_test_y$V1 == 1, 0, 1)
pc_test_y$V1 <- as.factor(pc_test_y$V1)
identical(pc_test_y$V1, dtm_test_y[,1])

###################### PCA CV ################

train.control <- trainControl(method = "cv", number = 10)
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

#Logistic regression directly on DTM
start_time <- Sys.time()
model <- train(V1 ~ ., data = pc_train_y, 
               trControl = train.control, method = "glm",
               family="binomial", control = list(maxit = 50))
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(pc_test_y)
confusionMatrix(predictions, pc_test_y$V1) 

#Linear Discriminant Analysis directly on DTM
start_time <- Sys.time()
model <- train(V1 ~ ., data = pc_train_y, 
               trControl = train.control, method = "lda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(pc_test_y)
confusionMatrix(predictions, pc_test_y$V1)

#Quadratic Discriminant Analysis directly on DTM
start_time <- Sys.time()
model <- train(V1 ~ ., data = pc_train_y, 
               trControl = train.control, method = "qda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(pc_test_y)
confusionMatrix(predictions, pc_test_y$V1)

#Mixture Discriminant Analysis directly on DTM
library(mda)
start_time <- Sys.time()
model <- train(V1 ~ ., data = pc_train_y, 
               trControl = train.control, method = "mda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(pc_test_y)
confusionMatrix(predictions, pc_test_y$V1)

#Flexible Discriminant Analysis directly on DTM
library(earth)
start_time <- Sys.time()
model <- train(V1 ~ ., data = pc_train_y, 
               trControl = train.control, method = "fda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(pc_test_y)
confusionMatrix(predictions, pc_test_y$V1)

#Classification trees directly on DTM
library(rpart)
start_time <- Sys.time()
cpGrid <- expand.grid(.cp=seq(0.01, 0.5,0.01))
model <- train(V1 ~ ., data = pc_train_y, 
               trControl = train.control, method = "rpart",
               tuneGrid = cpGrid)
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(pc_test_y)
confusionMatrix(predictions, pc_test_y$V1)

### Random Forest
library(randomForest)
start_time <- Sys.time()
mtry <- floor(sqrt(ncol(pc_train_y)-1))
if (mtry > 10){
  a <- mtry - 10
} else {a <- mtry}
b <- mtry + 10
mtryGrid <- expand.grid(.mtry=seq(a, b, 1))
model <- train(V1 ~ ., data = pc_train_y, 
               trControl = train.control, method = "rf",
               tuneGrid = mtryGrid)
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(pc_test_y)
confusionMatrix(predictions, pc_test_y$V1)
```

*TF-IDF*

```
library(tidyverse)
library(tidytext)
library(textdata)
library(text2vec)
library(keras)
library(uwot)
library(tensorflow)
library(nomclust)
library(ggplot2)
library(caret)
library(doParallel)

set.seed(121565)

############## COMBINING DATA SETS ############################

rawdata_train <- read.csv(file = "/work/wtp/jhaus4/fnn_train.csv", 
                          header = T,
                          stringsAsFactors = F)
rawdata_test <- read.csv(file = "/work/wtp/jhaus4/fnn_test.csv", 
                         header = T,
                         stringsAsFactors = F)
rawdata_valid <- read.csv(file = "/work/wtp/jhaus4/fnn_dev.csv", 
                          header = T,
                          stringsAsFactors = F)
rawdata <- rbind(rawdata_train, rawdata_valid, rawdata_test)

data <- rawdata %>%
  mutate(newsTextClean=gsub('[[:punct:]]+', '',
                       gsub('\\\\n|\\.|\\,|\\;',' ',
                       gsub("[^[:alnum:]]", " ",
                       (substr(statement,1,nchar(statement)-1))))))
#For all lowercase
#tolower(substr(statement,1,nchar(statement)-1))

news_tokens <- data %>% select(id, label_fnn, newsTextClean) %>%
  unnest_tokens(word, newsTextClean, to_lower = FALSE) %>%
  #Use just "[a-z']+" for lower case letters
  #Change to "[[:alnum:]]+" for numbers and cases to be included
  #Change to "[A-z']+" for all cases
  mutate(word = str_extract(word, "[[:alnum:]]+"))
news_tokens <- news_tokens %>% drop_na(word)
#news_tokens <- news_tokens %>% anti_join(stop_words)

news_new <- news_tokens %>% group_by(word) %>%
  mutate(token_freq = n()) %>%
  filter(token_freq >=60) %>%
  group_by(id, label_fnn) %>%
  summarise(newsTextClean = str_c(word, collapse = " "))

#Getting the labels
y <- news_new %>% select(label_fnn) %>% pull() %>% as.array()
y <- as.factor(y)
levels(y)
y <- ifelse(y == "fake", 0, 1)

it <- itoken(news_new$newsTextClean,
             tokenizer = word_tokenizer,
             ids = news_new$id,
             progressbar = T, tolower = FALSE)
vocab <- create_vocabulary(it)
vocab <- prune_vocabulary(vocab)
vectorizer <- vocab_vectorizer(vocab)
news_new <- news_new %>% select(newsTextClean) %>% pull()

#Vectorize tokens - token receiving a unique integer
tokenizer <- text_tokenizer(lower = FALSE) %>% 
                fit_text_tokenizer(news_new)

#put integers in a sequence
sequences<- texts_to_sequences(tokenizer, news_new)

library(MASS)

#Document-term matrix all
un.words <- length(tokenizer$word_index)
docs <- length(sequences)
dtm <- matrix(0, nrow = docs, ncol = un.words)
for (i in 1:docs){
  word.vec <- sequences[[i]]
  c <- length(sequences[[i]])
  a <- 0
  for (j in 1:c){
    a <- a + 1
    b <- word.vec[a]
    dtm[i,b] <- dtm[i,b] + 1
  }
}

dtm_y <- cbind(y, dtm)
dtm_y <- as.data.frame(dtm_y)

words <- unlist(tokenizer$index_word, use.names = TRUE)
words <- c("PolitiFactRating", words)

colnames(dtm_y) <- words

trainIndex <- createDataPartition(dtm_y$PolitiFactRating, 
                p = .8, list = F, times = 1)

dtm_train_y <- dtm_y[trainIndex,]
dtm_test_y <- dtm_y[-trainIndex,]

mean(dtm_train_y$PolitiFactRating)
mean(dtm_test_y$PolitiFactRating)

dtm_train_y$PolitiFactRating <- as.factor(dtm_train_y$PolitiFactRating)
dtm_test_y$PolitiFactRating <- as.factor(dtm_test_y$PolitiFactRating)

dim(dtm_train_y)

#Term Frequency
tf_train <- t(apply(dtm_train_y[,-1],1,function(x) x/sum(x)))
tf_test <- t(apply(dtm_test_y[,-1],1,function(x) x/sum(x)))

#IDF
idf_train <- t(apply(dtm_train_y[,-1], 2, function(x) 
  log(nrow(dtm_train_y)/sum(x != 0))))

#TF-IDF
tf.idf.train <- t(apply(tf_train, 1, function(x) x*idf_train))
tf.idf.test <- t(apply(tf_test, 1, function(x) x*idf_train))

dtm_train_y <- cbind(tf.idf.train, dtm_train_y[,1])
dtm_train_y <- as.data.frame(dtm_train_y)

dtm_test_y <- cbind(tf.idf.test, dtm_test_y[,1])
dtm_test_y <- as.data.frame(dtm_test_y)

words <- unlist(tokenizer$index_word, use.names = TRUE)
words <- c(words, "PolitiFactRating")

colnames(dtm_train_y) <- words
colnames(dtm_test_y) <- words

dtm_train_y$PolitiFactRating <- as.factor(dtm_train_y$PolitiFactRating)
dtm_test_y$PolitiFactRating <- as.factor(dtm_test_y$PolitiFactRating)
levels(dtm_train_y$PolitiFactRating)

dtm_train_y$PolitiFactRating <- 
          ifelse(dtm_train_y$PolitiFactRating == 1, 0, 1)
dtm_train_y$PolitiFactRating <- as.factor(dtm_train_y$PolitiFactRating)

dtm_test_y$PolitiFactRating <- 
          ifelse(dtm_test_y$PolitiFactRating == 1, 0, 1)
dtm_test_y$PolitiFactRating <- as.factor(dtm_test_y$PolitiFactRating)

levels(dtm_train_y$PolitiFactRating)

###################### TF-IDF CV ################

train.control <- trainControl(method = "cv", number = 10)
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

#Logistic regression directly on DTM
start_time <- Sys.time()
model <- train(PolitiFactRating ~ ., data = dtm_train_y, 
               trControl = train.control, method = "glm",
               family="binomial", control = list(maxit = 50))
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$PolitiFactRating)

#Linear Discriminant Analysis directly on DTM
start_time <- Sys.time()
model <- train(PolitiFactRating ~ ., data = dtm_train_y, 
               trControl = train.control, method = "lda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$PolitiFactRating)

#Quadratic Discriminant Analysis directly on DTM
#start_time <- Sys.time()
#model <- train(PolitiFactRating ~ ., data = dtm_train_y, 
#               trControl = train.control, method = "qda")
#end_time <- Sys.time()
#glm.time <- end_time - start_time
#glm.time
#model
#predictions <- model %>% predict(dtm_test_y)
#confusionMatrix(predictions,dtm_test_y$PolitiFactRating)


#Mixture Discriminant Analysis directly on DTM
library(mda)
#start_time <- Sys.time()
#model <- train(PolitiFactRating ~ ., data = dtm_train_y, 
#               trControl = train.control, method = "mda")
#end_time <- Sys.time()
#glm.time <- end_time - start_time
#glm.time
#model
#predictions <- model %>% predict(dtm_test_y)
#confusionMatrix(predictions,dtm_test_y$PolitiFactRating)


#Flexible Discriminant Analysis directly on DTM
library(earth)
#start_time <- Sys.time()
#model <- train(PolitiFactRating ~ ., data = dtm_train_y, 
#               trControl = train.control, method = "fda")
#end_time <- Sys.time()
#glm.time <- end_time - start_time
#glm.time
#model
#predictions <- model %>% predict(dtm_test_y)
#confusionMatrix(predictions,dtm_test_y$PolitiFactRating)

#Classification trees directly on DTM
library(rpart)
start_time <- Sys.time()
cpGrid <- expand.grid(.cp=seq(0.01, 0.5,0.01))
model <- train(PolitiFactRating ~ ., data = dtm_train_y, 
               trControl = train.control, method = "rpart",
               tuneGrid = cpGrid)
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$PolitiFactRating)


### Random Forest
library(randomForest)
start_time <- Sys.time()
mtry <- floor(sqrt(ncol(dtm_train_y)-1))
if (mtry > 10){
  a <- mtry - 10
} else {a <- mtry}
b <- mtry + 10
mtryGrid <- expand.grid(.mtry=seq(a, b, 1))
model <- train(PolitiFactRating ~ ., data = dtm_train_y, 
               trControl = train.control, method = "rf",
               tuneGrid = mtryGrid)
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$PolitiFactRating)
```

*Word2Vec Continuous Bag of Words*

```
library(tidyverse)
library(tidytext)
library(textdata)
library(text2vec)
library(keras)
library(uwot)
library(tensorflow)
library(nomclust)
library(ggplot2)
library(word2vec)
library(caret)
library(doParallel)

set.seed(121565)

rawdata_train <- read.csv(file = "/work/wtp/jhaus4/fnn_train.csv", 
                          header = T,
                          stringsAsFactors = F)
rawdata_test <- read.csv(file = "/work/wtp/jhaus4/fnn_test.csv", 
                         header = T,
                         stringsAsFactors = F)
rawdata_valid <- read.csv(file = "/work/wtp/jhaus4/fnn_dev.csv", 
                          header = T,
                          stringsAsFactors = F)
rawdata <- rbind(rawdata_train, rawdata_valid, rawdata_test)

data <- rawdata %>%
  mutate(newsTextClean=gsub('[[:punct:]]+', '',
                       gsub('\\\\n|\\.|\\,|\\;',' ',
                       gsub("[^[:alnum:]]", " ",
                       (substr(statement,1,nchar(statement)-1))))))

news_tokens <- data %>% select(id, label_fnn, newsTextClean) %>%
  unnest_tokens(word, newsTextClean, to_lower = FALSE) %>%
  #Use just "[a-z']+" for lower case letters
  #Change to "[[:alnum:]]+" for numbers to be included
  #"[A-z']+"
  mutate(word = str_extract(word, "[[:alnum:]]+"))
news_tokens <- news_tokens %>% drop_na(word)
#news_tokens <- news_tokens %>% anti_join(stop_words)

news_new <- news_tokens %>% group_by(word) %>%
  mutate(token_freq = n()) %>%
  filter(token_freq >= 60) %>%
  group_by(id, label_fnn) %>%
  summarise(newsTextClean = str_c(word, collapse = " "))

#Use just "[a-z']+" for lower case letters
#Change to "[[:alnum:]]+" for numbers to be included
max.length <- max(str_count(news_new$newsTextClean, "[[:alnum:]]+"))

trainIndex <- createDataPartition(news_new$label_fnn, 
                p = .8, list = F, times = 1)
train.control <- trainControl(method = "cv", number = 10)

news_new_train <- news_new[trainIndex,]
news_new_test <- news_new[-trainIndex,]

#Getting the labels
y_train <- news_new_train %>% select(label_fnn) %>% pull() %>% as.array()
y_test <- news_new_test %>% select(label_fnn) %>% pull() %>% as.array()
y_train <- as.factor(y_train)
y_test <- as.factor(y_test)
levels(y_train)
levels(y_test)
y_train <- ifelse(y_train == "fake", 0, 1)
y_test <- ifelse(y_test == "fake", 0, 1)

it_train <- itoken(news_new_train$newsTextClean,
             tokenizer = word_tokenizer,
             ids = news_new$id,
             progressbar = T, tolower = FALSE)
it_test <- itoken(news_new_test$newsTextClean,
                   tokenizer = word_tokenizer,
                   ids = news_new$id,
                   progressbar = T, tolower = FALSE)
vocab_train <- create_vocabulary(it_train)
vocab_test <- create_vocabulary(it_test)
vocab_train <- prune_vocabulary(vocab_train)
vocab_test <- prune_vocabulary(vocab_test)
vectorizer_train <- vocab_vectorizer(vocab_train)
vectorizer_test <- vocab_vectorizer(vocab_test)
news_new_train <- news_new_train %>% select(newsTextClean) %>% pull()
news_new_test <- news_new_test %>% select(newsTextClean) %>% pull()

#Vectorize tokens - token receiving a unique integer
tokenizer_train <- text_tokenizer(lower = FALSE) %>% 
                    fit_text_tokenizer(news_new_train)
tokenizer_test <- text_tokenizer(lower = FALSE) %>% 
                    fit_text_tokenizer(news_new_test)

#put integers in a sequence
sequences_train <- texts_to_sequences(tokenizer_train, news_new_train)
sequences_test <- texts_to_sequences(tokenizer_test, news_new_test)

dtm_train <- create_dtm(it_train, vectorizer_train)
dtm_train <- as.matrix(dtm_train)
dtm_test <- create_dtm(it_test, vectorizer_test)
dtm_test <- as.matrix(dtm_test)

############WORD2VEC WITH 300 DIM##################
model_train <- word2vec(x = news_new_train, dim = 300, iter = 100, 
                min_count = 0L)
model_train$success
emb_train <- as.matrix(model_train)
emb_train[1:5, 1:5]
emb_train_ord <- emb_train[order(rownames(emb_train)),]
emb_train_ord[1:5, 1:5]

### Getting embeddings per document
intersection <- colnames(dtm_train) %in% rownames(emb_train_ord)
dtm_train <- dtm_train[,intersection]
words <- colnames(dtm_train)
dtm_emb_train <- matrix(0, nrow = nrow(dtm_train), 
                  ncol = ncol(emb_train_ord))
for (i in 1:nrow(dtm_train)){
 for (j in 1:ncol(dtm_train)){
   if (dtm_train[i,j] != 0){
     dtm_emb_train[i,] <- dtm_emb_train[i,] + dtm_train[i,j] * 
       emb_train_ord[which(rownames(emb_train_ord) == words[j]),]
   }
 }
}
dtm_emb_train[1:5, 1:5]
max(dtm_emb_train)

int_test <- colnames(dtm_test) %in% rownames(emb_train_ord)
dtm_test <- dtm_test[,int_test]
words_test <- colnames(dtm_test)
dtm_emb_test <- matrix(0, nrow = nrow(dtm_test), 
                ncol = ncol(emb_train_ord))
for (i in 1:nrow(dtm_test)){
 for (j in 1:ncol(dtm_test)){
   if (dtm_test[i,j] != 0){
     dtm_emb_test[i,] <- dtm_emb_test[i,] + dtm_test[i,j] * 
       emb_train_ord[which(rownames(emb_train_ord) == words_test[j]),]
   }
 }
}
dtm_emb_test[1:5, 1:5]
max(dtm_emb_test)

dtm_train_y <- cbind(dtm_emb_train, y_train)
dtm_train_y <- as.data.frame(dtm_train_y)
dtm_test_y <- cbind(dtm_emb_test, y_test)
dtm_test_y <- as.data.frame(dtm_test_y)

dtm_train_y$y_train <- as.factor(dtm_train_y$y_train)
dtm_test_y$y_test <- as.factor(dtm_test_y$y_test)

train.control <- trainControl(method = "cv", number = 10)
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

 ##### CV 300 DIM#####

# #Logistic regression directly on DTM
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "glm",
              family="binomial", control = list(maxit = 50))
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Linear Discriminant Analysis directly on DTM
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "lda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Quadratic Discriminant Analysis directly on DTM
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "qda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

# #Mixture Discriminant Analysis directly on DTM
library(mda)
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "mda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

# #Flexible Discriminant Analysis directly on DTM
library(earth)
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "fda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

# #Classification trees directly on DTM
library(rpart)
start_time <- Sys.time()
cpGrid <- expand.grid(.cp=seq(0.01, 0.5,0.01))
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "rpart",
              tuneGrid = cpGrid)
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

# ### Random Forest
library(randomForest)
start_time <- Sys.time()
mtry <- floor(sqrt(ncol(dtm_train_y)-1))
if (mtry > 10){
 a <- mtry - 10
} else {a <- mtry}
b <- mtry + 10
mtryGrid <- expand.grid(.mtry=seq(a, b, 1))
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "rf",
              tuneGrid = mtryGrid)
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)
```

*Word2Vec Skip-Gram*

```
library(tidyverse)
library(tidytext)
library(textdata)
library(text2vec)
library(keras)
library(uwot)
library(tensorflow)
library(nomclust)
library(ggplot2)
library(word2vec)
library(caret)
library(doParallel)

set.seed(121565)

rawdata_train <- read.csv(file = "/work/wtp/jhaus4/fnn_train.csv", 
                          header = T,
                          stringsAsFactors = F)
rawdata_test <- read.csv(file = "/work/wtp/jhaus4/fnn_test.csv", 
                          header = T,
                         stringsAsFactors = F)
rawdata_valid <- read.csv(file = "/work/wtp/jhaus4/fnn_dev.csv", 
                          header = T,
                          stringsAsFactors = F)
rawdata <- rbind(rawdata_train, rawdata_valid, rawdata_test)

data <- rawdata %>%
  mutate(newsTextClean=gsub('[[:punct:]]+', '',
                       gsub('\\\\n|\\.|\\,|\\;',' ',
                       gsub("[^[:alnum:]]", " ",
                       (substr(statement,1,nchar(statement)-1))))))

news_tokens <- data %>% select(id, label_fnn, newsTextClean) %>%
  unnest_tokens(word, newsTextClean, to_lower = FALSE) %>%
  #Use just "[a-z']+" for lower case letters
  #Change to "[[:alnum:]]+" for numbers to be included
  #"[A-z']+"
  mutate(word = str_extract(word, "[[:alnum:]]+"))
news_tokens <- news_tokens %>% drop_na(word)
#news_tokens <- news_tokens %>% anti_join(stop_words)

news_new <- news_tokens %>% group_by(word) %>%
  mutate(token_freq = n()) %>%
  filter(token_freq >= 60) %>%
  group_by(id, label_fnn) %>%
  summarise(newsTextClean = str_c(word, collapse = " "))

#Use just "[a-z']+" for lower case letters
#Change to "[[:alnum:]]+" for numbers to be included
max.length <- max(str_count(news_new$newsTextClean, "[[:alnum:]]+"))

trainIndex <- createDataPartition(news_new$label_fnn, 
                p = .8, list = F, times = 1)
train.control <- trainControl(method = "cv", number = 10)
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

news_new_train <- news_new[trainIndex,]
news_new_test <- news_new[-trainIndex,]

#Getting the labels
y_train <- news_new_train %>% select(label_fnn) %>% pull() %>% as.array()
y_test <- news_new_test %>% select(label_fnn) %>% pull() %>% as.array()
y_train <- as.factor(y_train)
y_test <- as.factor(y_test)
levels(y_train)
levels(y_test)
y_train <- ifelse(y_train == "fake", 0, 1)
y_test <- ifelse(y_test == "fake", 0, 1)

it_train <- itoken(news_new_train$newsTextClean,
                   tokenizer = word_tokenizer,
                   ids = news_new$id,
                   progressbar = T, tolower = FALSE)
it_test <- itoken(news_new_test$newsTextClean,
                  tokenizer = word_tokenizer,
                  ids = news_new$id,
                  progressbar = T, tolower = FALSE)
vocab_train <- create_vocabulary(it_train)
vocab_test <- create_vocabulary(it_test)
vocab_train <- prune_vocabulary(vocab_train)
vocab_test <- prune_vocabulary(vocab_test)
vectorizer_train <- vocab_vectorizer(vocab_train)
vectorizer_test <- vocab_vectorizer(vocab_test)
news_new_train <- news_new_train %>% select(newsTextClean) %>% pull()
news_new_test <- news_new_test %>% select(newsTextClean) %>% pull()

#Vectorize tokens - token receiving a unique integer
tokenizer_train <- text_tokenizer(lower = FALSE) %>% 
                    fit_text_tokenizer(news_new_train)
tokenizer_test <- text_tokenizer(lower = FALSE) %>% 
                    fit_text_tokenizer(news_new_test)

#put integers in a sequence
sequences_train <- texts_to_sequences(tokenizer_train, news_new_train)
sequences_test <- texts_to_sequences(tokenizer_test, news_new_test)

dtm_train <- create_dtm(it_train, vectorizer_train)
dtm_train <- as.matrix(dtm_train)
dtm_test <- create_dtm(it_test, vectorizer_test)
dtm_test <- as.matrix(dtm_test)

############WORD2VEC SG WITH 300 DIM##################
model_train <- word2vec(x = news_new_train, type = "skip-gram", 
                        dim = 300, iter = 100, min_count = 0L)
model_train$success
emb_train <- as.matrix(model_train)
emb_train_ord <- emb_train[order(rownames(emb_train)),]

### Getting embeddings per document
intersection <- colnames(dtm_train) %in% rownames(emb_train_ord)
dtm_train <- dtm_train[,intersection]
words <- colnames(dtm_train)
dtm_emb_train <- matrix(0, nrow = nrow(dtm_train), 
                  ncol = ncol(emb_train_ord))
for (i in 1:nrow(dtm_train)){
  for (j in 1:ncol(dtm_train)){
    if (dtm_train[i,j] != 0){
      dtm_emb_train[i,] <- dtm_emb_train[i,] + dtm_train[i,j] * 
        emb_train_ord[which(rownames(emb_train_ord) == words[j]),]
    }
  }
}

int_test <- colnames(dtm_test) %in% rownames(emb_train_ord)
dtm_test <- dtm_test[,int_test]
words_test <- colnames(dtm_test)
dtm_emb_test <- matrix(0, nrow = nrow(dtm_test), 
                  ncol = ncol(emb_train_ord))
for (i in 1:nrow(dtm_test)){
  for (j in 1:ncol(dtm_test)){
    if (dtm_test[i,j] != 0){
      dtm_emb_test[i,] <- dtm_emb_test[i,] + dtm_test[i,j] * 
        emb_train_ord[which(rownames(emb_train_ord) == words_test[j]),]
    }
  }
}

dtm_train_y <- cbind(dtm_emb_train, y_train)
dtm_train_y <- as.data.frame(dtm_train_y)
dtm_test_y <- cbind(dtm_emb_test, y_test)
dtm_test_y <- as.data.frame(dtm_test_y)

dtm_train_y$y_train <- as.factor(dtm_train_y$y_train)
dtm_test_y$y_test <- as.factor(dtm_test_y$y_test)

##### CV 300 DIM#####

#Logistic regression directly on DTM
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "glm",
               family="binomial", control = list(maxit = 50))
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Linear Discriminant Analysis directly on DTM
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "lda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Quadratic Discriminant Analysis directly on DTM
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "qda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Mixture Discriminant Analysis directly on DTM
library(mda)
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "mda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Flexible Discriminant Analysis directly on DTM
library(earth)
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "fda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Classification trees directly on DTM
library(rpart)
start_time <- Sys.time()
cpGrid <- expand.grid(.cp=seq(0.01, 0.5,0.01))
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "rpart",
               tuneGrid = cpGrid)
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

### Random Forest
library(randomForest)
start_time <- Sys.time()
mtry <- floor(sqrt(ncol(dtm_train_y)-1))
if (mtry > 10){
  a <- mtry - 10
} else {a <- mtry}
b <- mtry + 10
mtryGrid <- expand.grid(.mtry=seq(a, b, 1))
model <- train(y_train ~ ., data = dtm_train_y,
               trControl = train.control, method = "rf",
               tuneGrid = mtryGrid)
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)
```

**Multi-Class Classification**

*BERT*

```
library(tidyverse)
library(tidytext)
library(textdata)
library(text2vec)
library(keras)
library(uwot)
library(tensorflow)
library(nomclust)
library(ggplot2)
library(caret)
library(doParallel)
library(nnet)

set.seed(121565)

fnn_train <- read.csv(file = "/work/wtp/jhaus4/fnn_train.csv", 
                      header = T,
                      stringsAsFactors = F)
fnn_test <- read.csv(file = "/work/wtp/jhaus4/fnn_test.csv", 
                      header = T,
                     stringsAsFactors = F)
fnn_valid <- read.csv(file = "/work/wtp/jhaus4/fnn_dev.csv", 
                      header = T,
                      stringsAsFactors = F)
fnn <- rbind(fnn_train, fnn_valid, fnn_test)

LIAR_train <- read.csv(file = "/work/wtp/jhaus4/liar_train.csv", 
                        header = T,
                       stringsAsFactors = F)
LIAR_test <- read.csv(file = "/work/wtp/jhaus4/liar_test.csv", 
                      header = T,
                      stringsAsFactors = F)
LIAR_valid <- read.csv(file = "/work/wtp/jhaus4/liar_dev.csv", 
                        header = T,
                       stringsAsFactors = F)
LIAR <- rbind(LIAR_train, LIAR_valid, LIAR_test)

common <- intersect(fnn$id, LIAR$id) 
rawdata <- LIAR[LIAR$id %in% common, ]

data <- rawdata %>%
  mutate(newsTextClean=gsub('[[:punct:]]+', '',
                       gsub('\\\\n|\\.|\\,|\\;',' ',
                       gsub("[^[:alnum:]]", " ",
                       tolower(substr(statement,1,nchar(statement)-1))))))

data <- data %>% separate(date, 
                  c("Year", "Month", "Day","Junk"), sep = "-")
#For all lowercase
#tolower(substr(statement,1,nchar(statement)-1))

news_tokens <- data %>% select(id, label.liar, Year, newsTextClean) %>%
  unnest_tokens(word, newsTextClean, to_lower = FALSE) %>%
  #Use just "[a-z']+" for lower case letters
  mutate(word = str_extract(word, "[a-z']+"))
news_tokens <- news_tokens %>% drop_na(word)
#news_tokens <- news_tokens %>% anti_join(stop_words)

news_new <- news_tokens %>% group_by(word) %>%
  mutate(token_freq = n()) %>%
  filter(token_freq >= 60) %>%
  group_by(id, label.liar, Year) %>%
  summarise(newsTextClean = str_c(word, collapse = " "))

trainIndex <- createDataPartition(news_new$label.liar,
                                  p = .8, list = F, times = 1)
train.control <- trainControl(method = "cv", number = 10)
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

news_new_train <- news_new[trainIndex,]
news_new_test <- news_new[-trainIndex,]

#write.csv(news_new_train, "liartrain60Stopwords.csv", row.names = FALSE)
#write.csv(news_new_test, "liartest60Stopwords.csv", row.names = FALSE)

bert_train <- read.csv(file = "BERT_LIAR_Train_60_Stopwords.csv",
                       header = F)
dim(bert_train)
bert_train <- bert_train[-1,]
dim(bert_train)

bert_test <- read.csv(file = "BERT_LIAR_Test_60_Stopwords.csv", 
                      header = F)
dim(bert_test)
bert_test <- bert_test[-1,]
dim(bert_test)

#Getting the labels
y_train <- news_new_train %>% select(label.liar) %>% 
  pull() %>% as.array()
y_test <- news_new_test %>% select(label.liar) %>% 
  pull() %>% as.array()
y_train <- as.factor(y_train)
y_test <- as.factor(y_test)
levels(y_train)
levels(y_test)
levels(y_train) <- c("true", "mostly-true", "half-true", 
                     "barely-true", "false", "pants-fire")
levels(y_test) <- c("true", "mostly-true", "half-true", 
                    "barely-true", "false", "pants-fire")

#year_train <- news_new_train %>% select(Year) %>% pull() %>% as.array()
#year_test <- news_new_test %>% select(Year) %>% pull() %>% as.array()
#year_train <- as.factor(year_train)
#year_test <- as.factor(year_test)
#levels(year_train)
#levels(year_test)

dtm_train_y <- cbind(bert_train, y_train)
dtm_train_y <- as.data.frame(dtm_train_y)
dtm_test_y <- cbind(bert_test, y_test)
dtm_test_y <- as.data.frame(dtm_test_y)
#dtm_test_y <- dtm_test_y %>% rename("year_train"="year_test")

dtm_train_y$y_train <- as.factor(dtm_train_y$y_train)
dtm_test_y$y_test <- as.factor(dtm_test_y$y_test)
#dtm_train_y$year_train <- as.factor(dtm_train_y$year_train)
#dtm_test_y$year_train <- as.factor(dtm_test_y$year_train)

##### CV DIM#####

#Ordinal Logistic regression
library(MASS)
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "polr",
               control = list(maxit = 100))
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Linear Discriminant Analysis directly on DTM
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "lda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Quadratic Discriminant Analysis directly on DTM
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "qda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Mixture Discriminant Analysis directly on DTM
library(mda)
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "mda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Flexible Discriminant Analysis directly on DTM
library(earth)
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "fda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Classification trees directly on DTM
library(rpart)
start_time <- Sys.time()
cpGrid <- expand.grid(.cp=seq(0.01, 0.5,0.01))
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "rpart",
               tuneGrid = cpGrid)
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

### Random Forest
library(randomForest)
start_time <- Sys.time()
mtry <- floor(sqrt(ncol(dtm_train_y)-1))
if (mtry > 10){
  a <- mtry - 10
} else {a <- mtry}
b <- mtry + 10
mtryGrid <- expand.grid(.mtry=seq(a, b, 1))
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "rf",
               tuneGrid = mtryGrid)
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)
```

*GloVe*

```
library(tidyverse)
library(tidytext)
library(textdata)
library(text2vec)
library(keras)
library(uwot)
library(tensorflow)
library(nomclust)
library(ggplot2)
library(word2vec)
library(caret)
library(doParallel)
library(nnet)

set.seed(121565)

############## COMBINING DATA SETS ############################

fnn_train <- read.csv(file = "/work/wtp/jhaus4/fnn_train.csv", 
                      header = T,
                      stringsAsFactors = F)
fnn_test <- read.csv(file = "/work/wtp/jhaus4/fnn_test.csv", 
                      header = T,
                     stringsAsFactors = F)
fnn_valid <- read.csv(file = "/work/wtp/jhaus4/fnn_dev.csv", 
                      header = T,
                      stringsAsFactors = F)
fnn <- rbind(fnn_train, fnn_valid, fnn_test)

LIAR_train <- read.csv(file = "/work/wtp/jhaus4/liar_train.csv", 
                        header = T,
                       stringsAsFactors = F)
LIAR_test <- read.csv(file = "/work/wtp/jhaus4/liar_test.csv", 
                      header = T,
                      stringsAsFactors = F)
LIAR_valid <- read.csv(file = "/work/wtp/jhaus4/liar_dev.csv", 
                        header = T,
                       stringsAsFactors = F)
LIAR <- rbind(LIAR_train, LIAR_valid, LIAR_test)

common <- intersect(fnn$id, LIAR$id) 
rawdata <- LIAR[LIAR$id %in% common, ]


data <- rawdata %>%
  mutate(newsTextClean=gsub('[[:punct:]]+', '',
                       gsub('\\\\n|\\.|\\,|\\;',' ',
                       gsub("[^[:alnum:]]", " ",
                       tolower(substr(statement,1,nchar(statement)-1))))))

data <- data %>% separate(date, 
                  c("Year", "Month", "Day","Junk"), sep = "-")

news_tokens <- data %>% select(id, label.liar, Year, newsTextClean) %>%
  unnest_tokens(word, newsTextClean, to_lower = FALSE) %>%
  #Use just "[a-z']+" for lower case letters
  mutate(word = str_extract(word, "[a-z']+"))
news_tokens <- news_tokens %>% drop_na(word)
#news_tokens <- news_tokens %>% anti_join(stop_words)

news_new <- news_tokens %>% group_by(word) %>%
  mutate(token_freq = n()) %>%
  filter(token_freq >= 30) %>%
  group_by(id, label.liar, Year) %>%
  summarise(newsTextClean = str_c(word, collapse = " "))

max.length <- max(str_count(news_new$newsTextClean, "[a-z']+"))

trainIndex <- createDataPartition(news_new$label.liar, 
                p = .8, list = F, times = 1)
train.control <- trainControl(method = "cv", number = 10)
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

news_new_train <- news_new[trainIndex,]
news_new_test <- news_new[-trainIndex,]

#Getting the labels
y_train <- news_new_train %>% select(label.liar) %>% pull() %>% as.array()
y_test <- news_new_test %>% select(label.liar) %>% pull() %>% as.array()
y_train <- as.factor(y_train)
y_test <- as.factor(y_test)
levels(y_train)
levels(y_test)
#y_train <- relevel(y_train, ref = "true")
#y_test <- relevel(y_test, ref = "true")
levels(y_train) <- c("true", "mostly-true", "half-true", 
          "barely-true", "false", "pants-fire")
levels(y_test) <- c("true", "mostly-true", "half-true", 
          "barely-true", "false", "pants-fire")

#year_train <- news_new_train %>% select(Year) %>% pull() %>% as.array()
#year_test <- news_new_test %>% select(Year) %>% pull() %>% as.array()
#year_train <- as.factor(year_train)
#year_test <- as.factor(year_test)
#levels(year_train)
#levels(year_test)

it_train <- itoken(news_new_train$newsTextClean,
                   tokenizer = word_tokenizer,
                   ids = news_new$id,
                   progressbar = T, tolower = FALSE)
it_test <- itoken(news_new_test$newsTextClean,
                  tokenizer = word_tokenizer,
                  ids = news_new$id,
                  progressbar = T, tolower = FALSE)
vocab_train <- create_vocabulary(it_train)
vocab_test <- create_vocabulary(it_test)
vocab_train <- prune_vocabulary(vocab_train)
vocab_test <- prune_vocabulary(vocab_test)
vectorizer_train <- vocab_vectorizer(vocab_train)
vectorizer_test <- vocab_vectorizer(vocab_test)
news_new_train <- news_new_train %>% select(newsTextClean) %>% pull()
news_new_test <- news_new_test %>% select(newsTextClean) %>% pull()

#Vectorize tokens - token receiving a unique integer
tokenizer_train <- text_tokenizer(lower = FALSE) %>% 
      fit_text_tokenizer(news_new_train)
tokenizer_test <- text_tokenizer(lower = FALSE) %>% 
      fit_text_tokenizer(news_new_test)

#put integers in a sequence
sequences_train <- texts_to_sequences(tokenizer_train, news_new_train)
sequences_test <- texts_to_sequences(tokenizer_test, news_new_test)

dtm_train <- create_dtm(it_train, vectorizer_train)
dtm_train <- as.matrix(dtm_train)
dtm_test <- create_dtm(it_test, vectorizer_test)
dtm_test <- as.matrix(dtm_test)
tcm_train <- create_tcm(it_train, vectorizer_train,
                        skip_grams_window_context = c("symmetric"))
xmax <- max(tcm_train)

######################## GloVe Embedding Dim 300 ###############
glove_train <- GlobalVectors$new(rank = 300, x_max = xmax)
# This gets the embeddings for target words.
wv_tar_train <- glove_train$fit_transform(tcm_train, n_iter = 100)
dim(wv_tar_train)
# This gets the embedding for the context words.
wv_con_train <- glove_train$components
dim(wv_con_train)

word_vect_train <- wv_tar_train + t(wv_con_train)
dim(word_vect_train)
word_vect_train <- as.matrix(word_vect_train)

### Getting embeddings per document
intersection <- colnames(dtm_train) %in% rownames(word_vect_train)
dtm_train <- dtm_train[,intersection]
words <- colnames(dtm_train)
dtm_emb_train <- matrix(0, nrow = nrow(dtm_train), 
      ncol = ncol(word_vect_train))
for (i in 1:nrow(dtm_train)){
  for (j in 1:ncol(dtm_train)){
    if (dtm_train[i,j] != 0){
      dtm_emb_train[i,] <- dtm_emb_train[i,] + dtm_train[i,j] * 
        word_vect_train[which(rownames(word_vect_train) == words[j]),]
    }
  }
}

int_test <- colnames(dtm_test) %in% rownames(word_vect_train)
dtm_test <- dtm_test[,int_test]
words_test <- colnames(dtm_test)
dtm_emb_test <- matrix(0, nrow = nrow(dtm_test), 
      ncol = ncol(word_vect_train))
for (i in 1:nrow(dtm_test)){
  for (j in 1:ncol(dtm_test)){
    if (dtm_test[i,j] != 0){
      dtm_emb_test[i,] <- dtm_emb_test[i,] + dtm_test[i,j] * 
        word_vect_train[which(rownames(word_vect_train) == words_test[j]),]
    }
  }
}

dtm_train_y <- cbind(dtm_emb_train, y_train)
dtm_train_y <- as.data.frame(dtm_train_y)
dtm_test_y <- cbind(dtm_emb_test, y_test)
dtm_test_y <- as.data.frame(dtm_test_y)
#dtm_test_y <- dtm_test_y %>% rename("year_train"="year_test")

dtm_train_y$y_train <- as.factor(dtm_train_y$y_train)
dtm_test_y$y_test <- as.factor(dtm_test_y$y_test)
#dtm_train_y$year_train <- as.factor(dtm_train_y$year_train)
#dtm_test_y$year_test <- as.factor(dtm_test_y$year_test)

##### CV 300 DIM#####

#Ordinal Logistic regression
library(MASS)
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y,
               trControl = train.control, method = "polr",
               control = list(maxit = 100))
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test) 

#Linear Discriminant Analysis directly on DTM
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "lda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Quadratic Discriminant Analysis directly on DTM
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "qda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Mixture Discriminant Analysis directly on DTM
library(mda)
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "mda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Flexible Discriminant Analysis directly on DTM
library(earth)
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "fda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Classification trees directly on DTM
library(rpart)
start_time <- Sys.time()
cpGrid <- expand.grid(.cp=seq(0.01, 0.5,0.01))
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "rpart",
               tuneGrid = cpGrid)
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

### Random Forest
library(randomForest)
start_time <- Sys.time()
mtry <- floor(sqrt(ncol(dtm_train_y)-1))
if (mtry > 10){
  a <- mtry - 10
} else {a <- mtry}
b <- mtry + 10
mtryGrid <- expand.grid(.mtry=seq(a, b, 1))
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "rf",
               tuneGrid = mtryGrid)
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)
```

*PCA*

```
library(tidyverse)
library(tidytext)
library(textdata)
library(text2vec)
library(keras)
library(uwot)
library(tensorflow)
library(nomclust)
library(ggplot2)
library(caret)
library(doParallel)
library(nnet)

set.seed(121565)

fnn_train <- read.csv(file = "/work/wtp/jhaus4/fnn_train.csv", 
                      header = T,
                      stringsAsFactors = F)
fnn_test <- read.csv(file = "/work/wtp/jhaus4/fnn_test.csv", 
                      header = T,
                     stringsAsFactors = F)
fnn_valid <- read.csv(file = "/work/wtp/jhaus4/fnn_dev.csv", 
                      header = T,
                      stringsAsFactors = F)
fnn <- rbind(fnn_train, fnn_valid, fnn_test)

LIAR_train <- read.csv(file = "/work/wtp/jhaus4/liar_train.csv", 
                      header = T,
                       stringsAsFactors = F)
LIAR_test <- read.csv(file = "/work/wtp/jhaus4/liar_test.csv", 
                      header = T,
                      stringsAsFactors = F)
LIAR_valid <- read.csv(file = "/work/wtp/jhaus4/liar_dev.csv", 
                      header = T,
                       stringsAsFactors = F)
LIAR <- rbind(LIAR_train, LIAR_valid, LIAR_test)

common <- intersect(fnn$id, LIAR$id) 
rawdata <- LIAR[LIAR$id %in% common, ]


data <- rawdata %>%
  mutate(newsTextClean=gsub('[[:punct:]]+', '',
                       gsub('\\\\n|\\.|\\,|\\;',' ',
                       gsub("[^[:alnum:]]", " ",
                       tolower(substr(statement,1,nchar(statement)-1))))))

data <- data %>% separate(date, 
          c("Year", "Month", "Day","Junk"), sep = "-")

news_tokens <- data %>% select(id, label.liar, Year, newsTextClean) %>%
  unnest_tokens(word, newsTextClean, to_lower = FALSE) %>%
  #Use just "[a-z']+" for lower case letters
  mutate(word = str_extract(word, "[a-z']+"))
news_tokens <- news_tokens %>% drop_na(word)
#news_tokens <- news_tokens %>% anti_join(stop_words)

news_new <- news_tokens %>% group_by(word) %>%
  mutate(token_freq = n()) %>%
  #filter(token_freq >= 60) %>%
  group_by(id, label.liar, Year) %>%
  summarise(newsTextClean = str_c(word, collapse = " "))

#Getting the labels
y <- news_new %>% select(label.liar) %>% pull() %>% as.array()
y <- as.factor(y)
levels(y)
levels(y) <- c("true", "mostly-true", "half-true", 
      "barely-true", "false", "pants-fire")

#year <- news_new %>% select(Year) %>% pull() %>% as.array()
#year <- as.factor(year)
#levels(year)

it <- itoken(news_new$newsTextClean,
             tokenizer = word_tokenizer,
             ids = news_new$id,
             progressbar = T, tolower = F)
vocab <- create_vocabulary(it)
vocab <- prune_vocabulary(vocab)
vectorizer <- vocab_vectorizer(vocab)
news_new <- news_new %>% select(newsTextClean) %>% pull()

#Vectorize tokens - token receiving a unique integer
tokenizer <- text_tokenizer(lower = F) %>% fit_text_tokenizer(news_new)

#put integers in a sequence
sequences<- texts_to_sequences(tokenizer, news_new)

library(MASS)

#Document-term matrix all
un.words <- length(tokenizer$word_index)
docs <- length(sequences)
dtm <- matrix(0, nrow = docs, ncol = un.words)
for (i in 1:docs){
  word.vec <- sequences[[i]]
  c <- length(sequences[[i]])
  a <- 0
  for (j in 1:c){
    a <- a + 1
    b <- word.vec[a]
    dtm[i,b] <- dtm[i,b] + 1
  }
}

dtm_y <- cbind(y, dtm)
dtm_y <- as.data.frame(dtm_y)

words <- unlist(tokenizer$index_word, use.names = TRUE)
words <- c("PolitiFactRating", words)

colnames(dtm_y) <- words

trainIndex <- createDataPartition(dtm_y$PolitiFactRating, 
        p = .8, list = F, times = 1)

dtm_train_y <- dtm_y[trainIndex,]
dtm_test_y <- dtm_y[-trainIndex,]

dtm_train_y$PolitiFactRating <- as.factor(dtm_train_y$PolitiFactRating)
dtm_test_y$PolitiFactRating <- as.factor(dtm_test_y$PolitiFactRating)
#dtm_train_y$Year <- as.factor(dtm_train_y$Year)
#dtm_test_y$Year <- as.factor(dtm_test_y$Year)

dtm_train <- dtm_train_y[,-c(1)]
pca_train <- prcomp(dtm_train, center = T)
pct_train <- (pca_train$sdev^2/sum(pca_train$sdev^2))*100
sum(pct_train[1:2000])
embeds <- pca_train$rotation[,1:2000]
pc_train <- as.matrix(dtm_train) %*% as.matrix(embeds)

pc_train_y <- cbind(dtm_train_y[,c(1)],pc_train)
pc_train_y <- as.data.frame(pc_train_y)
names(pc_train_y)[names(pc_train_y) == 'V1'] <- 'PolitiFactRating'
pc_train_y$PolitiFactRating <- as.factor(pc_train_y$PolitiFactRating)

identical(pc_train_y$PolitiFactRating, dtm_train_y[,1])

pc_test <- as.matrix(dtm_test_y[,-c(1)]) %*% as.matrix(embeds)

pc_test_y <- cbind( dtm_test_y[,c(1)], pc_test)
pc_test_y <- as.data.frame(pc_test_y)
names(pc_test_y)[names(pc_test_y) == 'V1'] <- 'PolitiFactRating'
pc_test_y$PolitiFactRating <- as.factor(pc_test_y$PolitiFactRating)

identical(pc_test_y$PolitiFactRating, dtm_test_y[,1])

###################### PCA CV ################

train.control <- trainControl(method = "cv", number = 10)
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

#Ordinal Logistic regression
#library(MASS)
#start_time <- Sys.time()
#model <- train(PolitiFactRating ~ ., data = pc_train_y, 
#               trControl = train.control, method = "polr",
#               control = list(maxit = 100))
#end_time <- Sys.time()
#glm.time <- end_time - start_time
#glm.time
#model
#predictions <- model %>% predict(pc_test_y)
#confusionMatrix(predictions,pc_test_y$PolitiFactRating)

#Linear Discriminant Analysis directly on DTM
start_time <- Sys.time()
model <- train(PolitiFactRating ~ ., data = pc_train_y, 
               trControl = train.control, method = "lda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(pc_test_y)
confusionMatrix(predictions, pc_test_y$PolitiFactRating)

#Quadratic Discriminant Analysis directly on DTM
#start_time <- Sys.time()
#model <- train(PolitiFactRating ~ ., data = pc_train_y, 
#               trControl = train.control, method = "qda")
#end_time <- Sys.time()
#glm.time <- end_time - start_time
#glm.time
#model
#predictions <- model %>% predict(pc_test_y)
#confusionMatrix(predictions, pc_test_y$PolitiFactRating)

#Mixture Discriminant Analysis directly on DTM
library(mda)
start_time <- Sys.time()
model <- train(PolitiFactRating ~ ., data = pc_train_y, 
               trControl = train.control, method = "mda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(pc_test_y)
confusionMatrix(predictions, pc_test_y$PolitiFactRating)

#Flexible Discriminant Analysis directly on DTM
library(earth)
start_time <- Sys.time()
model <- train(PolitiFactRating ~ ., data = pc_train_y, 
               trControl = train.control, method = "fda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(pc_test_y)
confusionMatrix(predictions, pc_test_y$PolitiFactRating)

#Classification trees directly on DTM
library(rpart)
start_time <- Sys.time()
cpGrid <- expand.grid(.cp=seq(0.01, 0.5,0.01))
model <- train(PolitiFactRating ~ ., data = pc_train_y, 
               trControl = train.control, method = "rpart",
               tuneGrid = cpGrid)
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(pc_test_y)
confusionMatrix(predictions, pc_test_y$PolitiFactRating)

### Random Forest
library(randomForest)
start_time <- Sys.time()
mtry <- floor(sqrt(ncol(pc_train_y)-1))
if (mtry > 10){
  a <- mtry - 10
} else {a <- mtry}
b <- mtry + 10
mtryGrid <- expand.grid(.mtry=seq(a, b, 1))
model <- train(PolitiFactRating ~ ., data = pc_train_y, 
               trControl = train.control, method = "rf",
               tuneGrid = mtryGrid)
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(pc_test_y)
confusionMatrix(predictions, pc_test_y$PolitiFactRating)
```

*Word2Vec Continuous Bag of Words*

```
library(tidyverse)
library(tidytext)
library(textdata)
library(text2vec)
library(keras)
library(uwot)
library(tensorflow)
library(nomclust)
library(ggplot2)
library(word2vec)
library(caret)
library(doParallel)
library(nnet)

set.seed(121565)

fnn_train <- read.csv(file = "/work/wtp/jhaus4/fnn_train.csv", 
                      header = T,
                      stringsAsFactors = F)
fnn_test <- read.csv(file = "/work/wtp/jhaus4/fnn_test.csv", 
                      header = T,
                     stringsAsFactors = F)
fnn_valid <- read.csv(file = "/work/wtp/jhaus4/fnn_dev.csv", 
                      header = T,
                      stringsAsFactors = F)
fnn <- rbind(fnn_train, fnn_valid, fnn_test)

LIAR_train <- read.csv(file = "/work/wtp/jhaus4/liar_train.csv", 
                      header = T,
                       stringsAsFactors = F)
LIAR_test <- read.csv(file = "/work/wtp/jhaus4/liar_test.csv", 
                      header = T,
                      stringsAsFactors = F)
LIAR_valid <- read.csv(file = "/work/wtp/jhaus4/liar_dev.csv", 
                      header = T,
                       stringsAsFactors = F)
LIAR <- rbind(LIAR_train, LIAR_valid, LIAR_test)

common <- intersect(fnn$id, LIAR$id) 
rawdata <- LIAR[LIAR$id %in% common, ]

data <- rawdata %>%
  mutate(newsTextClean=gsub('[[:punct:]]+', '',
                       gsub('\\\\n|\\.|\\,|\\;',' ',
                       gsub("[^[:alnum:]]", " ",
                       tolower(substr(statement,1,nchar(statement)-1))))))

data <- data %>% separate(date, 
        c("Year", "Month", "Day","Junk"), sep = "-")

news_tokens <- data %>% select(id, label.liar, Year, newsTextClean) %>%
  unnest_tokens(word, newsTextClean, to_lower = FALSE) %>%
  #Use just "[a-z']+" for lower case letters
  mutate(word = str_extract(word, "[a-z']+"))
news_tokens <- news_tokens %>% drop_na(word)
#news_tokens <- news_tokens %>% anti_join(stop_words)

news_new <- news_tokens %>% group_by(word) %>%
  mutate(token_freq = n()) %>%
  filter(token_freq >= 30) %>%
  group_by(id, label.liar, Year) %>%
  summarise(newsTextClean = str_c(word, collapse = " "))

#Use just "[a-z']+" for lower case letters
max.length <- max(str_count(news_new$newsTextClean, "[a-z']+"))

trainIndex <- createDataPartition(news_new$label.liar, 
      p = .8, list = F, times = 1)
train.control <- trainControl(method = "cv", number = 10)
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

news_new_train <- news_new[trainIndex,]
news_new_test <- news_new[-trainIndex,]

#Getting the labels
y_train <- news_new_train %>% select(label.liar) %>% pull() %>% as.array()
y_test <- news_new_test %>% select(label.liar) %>% pull() %>% as.array()
y_train <- as.factor(y_train)
y_test <- as.factor(y_test)
levels(y_train)
levels(y_test)
levels(y_train) <- c("true", "mostly-true", "half-true", 
    "barely-true", "false", "pants-fire")
levels(y_test) <- c("true", "mostly-true", "half-true",
    "barely-true", "false", "pants-fire")

#year_train <- news_new_train %>% select(Year) %>% pull() %>% as.array()
#year_test <- news_new_test %>% select(Year) %>% pull() %>% as.array()
#year_train <- as.factor(year_train)
#year_test <- as.factor(year_test)
#levels(year_train)
#levels(year_test)

it_train <- itoken(news_new_train$newsTextClean,
             tokenizer = word_tokenizer,
             ids = news_new$id,
             progressbar = T, tolower = FALSE)
it_test <- itoken(news_new_test$newsTextClean,
                   tokenizer = word_tokenizer,
                   ids = news_new$id,
                   progressbar = T, tolower = FALSE)
vocab_train <- create_vocabulary(it_train)
vocab_test <- create_vocabulary(it_test)
vocab_train <- prune_vocabulary(vocab_train)
vocab_test <- prune_vocabulary(vocab_test)
vectorizer_train <- vocab_vectorizer(vocab_train)
vectorizer_test <- vocab_vectorizer(vocab_test)
news_new_train <- news_new_train %>% select(newsTextClean) %>% pull()
news_new_test <- news_new_test %>% select(newsTextClean) %>% pull()

#Vectorize tokens - token receiving a unique integer
tokenizer_train <- text_tokenizer(lower = FALSE) %>% 
    fit_text_tokenizer(news_new_train)
tokenizer_test <- text_tokenizer(lower = FALSE) %>% 
    fit_text_tokenizer(news_new_test)

#put integers in a sequence
sequences_train <- texts_to_sequences(tokenizer_train, news_new_train)
sequences_test <- texts_to_sequences(tokenizer_test, news_new_test)

dtm_train <- create_dtm(it_train, vectorizer_train)
dtm_train <- as.matrix(dtm_train)
dtm_test <- create_dtm(it_test, vectorizer_test)
dtm_test <- as.matrix(dtm_test)

############WORD2VEC WITH 300 DIM##################
model_train <- word2vec(x = news_new_train, dim = 300, iter = 100, 
    min_count = 0L)
model_train$success
emb_train <- as.matrix(model_train)
emb_train[1:5, 1:5]
emb_train_ord <- emb_train[order(rownames(emb_train)),]
emb_train_ord[1:5, 1:5]

### Getting embeddings per document
intersection <- colnames(dtm_train) %in% rownames(emb_train_ord)
dtm_train <- dtm_train[,intersection]
words <- colnames(dtm_train)
dtm_emb_train <- matrix(0, nrow = nrow(dtm_train), 
    ncol = ncol(emb_train_ord))
for (i in 1:nrow(dtm_train)){
 for (j in 1:ncol(dtm_train)){
   if (dtm_train[i,j] != 0){
     dtm_emb_train[i,] <- dtm_emb_train[i,] + dtm_train[i,j] * 
       emb_train_ord[which(rownames(emb_train_ord) == words[j]),]
   }
 }
}
dtm_emb_train[1:5, 1:5]
max(dtm_emb_train)

int_test <- colnames(dtm_test) %in% rownames(emb_train_ord)
dtm_test <- dtm_test[,int_test]
words_test <- colnames(dtm_test)
dtm_emb_test <- matrix(0, nrow = nrow(dtm_test), ncol = ncol(emb_train_ord))
for (i in 1:nrow(dtm_test)){
 for (j in 1:ncol(dtm_test)){
   if (dtm_test[i,j] != 0){
     dtm_emb_test[i,] <- dtm_emb_test[i,] + dtm_test[i,j] * 
       emb_train_ord[which(rownames(emb_train_ord) == words_test[j]),]
   }
 }
}
dtm_emb_test[1:5, 1:5]
max(dtm_emb_test)

dtm_train_y <- cbind(dtm_emb_train, y_train)
dtm_train_y <- as.data.frame(dtm_train_y)
dtm_test_y <- cbind(dtm_emb_test, y_test)
dtm_test_y <- as.data.frame(dtm_test_y)
#dtm_test_y <- dtm_test_y %>% rename("year_train"="year_test")

dtm_train_y$y_train <- as.factor(dtm_train_y$y_train)
dtm_test_y$y_test <- as.factor(dtm_test_y$y_test)
#dtm_train_y$year_train <- as.factor(dtm_train_y$year_train)
#dtm_test_y$year_test <- as.factor(dtm_test_y$year_test)

 ##### CV 300 DIM#####

#Ordinal Logistic regression
library(MASS)
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y,
               trControl = train.control, method = "polr",
               control = list(maxit = 100))
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Linear Discriminant Analysis directly on DTM
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "lda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Quadratic Discriminant Analysis directly on DTM
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "qda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

# #Mixture Discriminant Analysis directly on DTM
library(mda)
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "mda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

# #Flexible Discriminant Analysis directly on DTM
library(earth)
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "fda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

# #Classification trees directly on DTM
library(rpart)
start_time <- Sys.time()
cpGrid <- expand.grid(.cp=seq(0.01, 0.5,0.01))
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "rpart",
              tuneGrid = cpGrid)
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

# ### Random Forest
library(randomForest)
start_time <- Sys.time()
mtry <- floor(sqrt(ncol(dtm_train_y)-1))
if (mtry > 10){
 a <- mtry - 10
} else {a <- mtry}
b <- mtry + 10
mtryGrid <- expand.grid(.mtry=seq(a, b, 1))
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "rf",
              tuneGrid = mtryGrid)
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)
```

*Word2Vec Skip-Gram*

```
library(tidyverse)
library(tidytext)
library(textdata)
library(text2vec)
library(keras)
library(uwot)
library(tensorflow)
library(nomclust)
library(ggplot2)
library(word2vec)
library(caret)
library(doParallel)
library(nnet)

set.seed(121565)

fnn_train <- read.csv(file = "/work/wtp/jhaus4/fnn_train.csv", 
                      header = T,
                      stringsAsFactors = F)
fnn_test <- read.csv(file = "/work/wtp/jhaus4/fnn_test.csv", 
                      header = T,
                     stringsAsFactors = F)
fnn_valid <- read.csv(file = "/work/wtp/jhaus4/fnn_dev.csv", 
                      header = T,
                      stringsAsFactors = F)
fnn <- rbind(fnn_train, fnn_valid, fnn_test)

LIAR_train <- read.csv(file = "/work/wtp/jhaus4/liar_train.csv", 
                        header = T,
                       stringsAsFactors = F)
LIAR_test <- read.csv(file = "/work/wtp/jhaus4/liar_test.csv", 
                      header = T,
                      stringsAsFactors = F)
LIAR_valid <- read.csv(file = "/work/wtp/jhaus4/liar_dev.csv", 
                        header = T,
                       stringsAsFactors = F)
LIAR <- rbind(LIAR_train, LIAR_valid, LIAR_test)

common <- intersect(fnn$id, LIAR$id) 
rawdata <- LIAR[LIAR$id %in% common, ]

data <- rawdata %>%
  mutate(newsTextClean=gsub('[[:punct:]]+', '',
                       gsub('\\\\n|\\.|\\,|\\;',' ',
                       gsub("[^[:alnum:]]", " ",
                       tolower(substr(statement,1,nchar(statement)-1))))))

data <- data %>% separate(date, 
    c("Year", "Month", "Day","Junk"), sep = "-")

news_tokens <- data %>% select(id, label.liar, Year, newsTextClean) %>%
  unnest_tokens(word, newsTextClean, to_lower = FALSE) %>%
  #Use just "[a-z']+" for lower case letters
  mutate(word = str_extract(word, "[a-z']+"))
news_tokens <- news_tokens %>% drop_na(word)
#news_tokens <- news_tokens %>% anti_join(stop_words)

news_new <- news_tokens %>% group_by(word) %>%
  mutate(token_freq = n()) %>%
  filter(token_freq >= 30) %>%
  group_by(id, label.liar, Year) %>%
  summarise(newsTextClean = str_c(word, collapse = " "))

#Use just "[a-z']+" for lower case letters
max.length <- max(str_count(news_new$newsTextClean, "[a-z']+"))

trainIndex <- createDataPartition(news_new$label.liar, 
    p = .8, list = F, times = 1)
train.control <- trainControl(method = "cv", number = 10)
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

news_new_train <- news_new[trainIndex,]
news_new_test <- news_new[-trainIndex,]

#Getting the labels
y_train <- news_new_train %>% select(label.liar) %>% pull() %>% as.array()
y_test <- news_new_test %>% select(label.liar) %>% pull() %>% as.array()
y_train <- as.factor(y_train)
y_test <- as.factor(y_test)
levels(y_train)
levels(y_test)
levels(y_train) <- c("true", "mostly-true", "half-true", 
  "barely-true", "false", "pants-fire")
levels(y_test) <- c("true", "mostly-true", "half-true", 
  "barely-true", "false", "pants-fire")

#year_train <- news_new_train %>% select(Year) %>% pull() %>% as.array()
#year_test <- news_new_test %>% select(Year) %>% pull() %>% as.array()
#year_train <- as.factor(year_train)
#year_test <- as.factor(year_test)
#levels(year_train)
#levels(year_test)

it_train <- itoken(news_new_train$newsTextClean,
                   tokenizer = word_tokenizer,
                   ids = news_new$id,
                   progressbar = T, tolower = FALSE)
it_test <- itoken(news_new_test$newsTextClean,
                  tokenizer = word_tokenizer,
                  ids = news_new$id,
                  progressbar = T, tolower = FALSE)
vocab_train <- create_vocabulary(it_train)
vocab_test <- create_vocabulary(it_test)
vocab_train <- prune_vocabulary(vocab_train)
vocab_test <- prune_vocabulary(vocab_test)
vectorizer_train <- vocab_vectorizer(vocab_train)
vectorizer_test <- vocab_vectorizer(vocab_test)
news_new_train <- news_new_train %>% select(newsTextClean) %>% pull()
news_new_test <- news_new_test %>% select(newsTextClean) %>% pull()

#Vectorize tokens - token receiving a unique integer
tokenizer_train <- text_tokenizer(lower = FALSE) %>% 
    fit_text_tokenizer(news_new_train)
tokenizer_test <- text_tokenizer(lower = FALSE) %>% 
    fit_text_tokenizer(news_new_test)

#put integers in a sequence
sequences_train <- texts_to_sequences(tokenizer_train, news_new_train)
sequences_test <- texts_to_sequences(tokenizer_test, news_new_test)

dtm_train <- create_dtm(it_train, vectorizer_train)
dtm_train <- as.matrix(dtm_train)
dtm_test <- create_dtm(it_test, vectorizer_test)
dtm_test <- as.matrix(dtm_test)

############WORD2VEC SG WITH 300 DIM##################
model_train <- word2vec(x = news_new_train, type = "skip-gram", 
                        dim = 300, iter = 100, min_count = 0L)
model_train$success
emb_train <- as.matrix(model_train)
emb_train_ord <- emb_train[order(rownames(emb_train)),]

### Getting embeddings per document
intersection <- colnames(dtm_train) %in% rownames(emb_train_ord)
dtm_train <- dtm_train[,intersection]
words <- colnames(dtm_train)
dtm_emb_train <- matrix(0, nrow = nrow(dtm_train), 
  ncol = ncol(emb_train_ord))
for (i in 1:nrow(dtm_train)){
  for (j in 1:ncol(dtm_train)){
    if (dtm_train[i,j] != 0){
      dtm_emb_train[i,] <- dtm_emb_train[i,] + dtm_train[i,j] * 
        emb_train_ord[which(rownames(emb_train_ord) == words[j]),]
    }
  }
}

int_test <- colnames(dtm_test) %in% rownames(emb_train_ord)
dtm_test <- dtm_test[,int_test]
words_test <- colnames(dtm_test)
dtm_emb_test <- matrix(0, nrow = nrow(dtm_test), 
  ncol = ncol(emb_train_ord))
for (i in 1:nrow(dtm_test)){
  for (j in 1:ncol(dtm_test)){
    if (dtm_test[i,j] != 0){
      dtm_emb_test[i,] <- dtm_emb_test[i,] + dtm_test[i,j] * 
        emb_train_ord[which(rownames(emb_train_ord) == words_test[j]),]
    }
  }
}

dtm_train_y <- cbind(dtm_emb_train, y_train)
dtm_train_y <- as.data.frame(dtm_train_y)
dtm_test_y <- cbind(dtm_emb_test, y_test)
dtm_test_y <- as.data.frame(dtm_test_y)
#dtm_test_y <- dtm_test_y %>% rename("year_train"="year_test")

dtm_train_y$y_train <- as.factor(dtm_train_y$y_train)
dtm_test_y$y_test <- as.factor(dtm_test_y$y_test)
#dtm_train_y$year_train <- as.factor(dtm_train_y$year_train)
#dtm_test_y$year_test <- as.factor(dtm_test_y$year_test)

##### CV 300 DIM#####

#Ordinal Logistic regression
library(MASS)
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "polr",
               control = list(maxit = 100))
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Linear Discriminant Analysis directly on DTM
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "lda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Quadratic Discriminant Analysis directly on DTM
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "qda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Mixture Discriminant Analysis directly on DTM
library(mda)
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "mda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Flexible Discriminant Analysis directly on DTM
library(earth)
start_time <- Sys.time()
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "fda")
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

#Classification trees directly on DTM
library(rpart)
start_time <- Sys.time()
cpGrid <- expand.grid(.cp=seq(0.01, 0.5,0.01))
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "rpart",
               tuneGrid = cpGrid)
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)

### Random Forest
library(randomForest)
start_time <- Sys.time()
mtry <- floor(sqrt(ncol(dtm_train_y)-1))
if (mtry > 10){
  a <- mtry - 10
} else {a <- mtry}
b <- mtry + 10
mtryGrid <- expand.grid(.mtry=seq(a, b, 1))
model <- train(y_train ~ ., data = dtm_train_y, 
               trControl = train.control, method = "rf",
               tuneGrid = mtryGrid)
end_time <- Sys.time()
glm.time <- end_time - start_time
glm.time
model
predictions <- model %>% predict(dtm_test_y)
confusionMatrix(predictions,dtm_test_y$y_test)
```
